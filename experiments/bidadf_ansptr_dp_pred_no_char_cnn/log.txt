Number of params: 862200 (retrieval took 3.468582 secs)
Beginning training loop...
epoch 1, iter 100, loss 9.20204, smoothed loss 9.48721, grad norm 3.39328, param norm 51.37409, batch time 2.287
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 1, iter 200, loss 8.80507, smoothed loss 9.04531, grad norm 3.92026, param norm 51.45158, batch time 2.398
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 1, iter 300, loss 9.03469, smoothed loss 8.68458, grad norm 3.76572, param norm 51.52627, batch time 2.148
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 1, iter 400, loss 8.19961, smoothed loss 8.40656, grad norm 4.01266, param norm 51.59749, batch time 2.309
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 1, iter 500, loss 8.04951, smoothed loss 8.20661, grad norm 4.68099, param norm 51.66955, batch time 2.296
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 1, iter 600, loss 7.53770, smoothed loss 8.04241, grad norm 5.85402, param norm 51.74818, batch time 2.270
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 1, iter 700, loss 7.82939, smoothed loss 7.86670, grad norm 5.48031, param norm 51.83245, batch time 2.258
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 1, iter 800, loss 7.55436, smoothed loss 7.69312, grad norm 5.71258, param norm 51.91347, batch time 2.217
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 1, iter 900, loss 7.76929, smoothed loss 7.58532, grad norm 6.83244, param norm 51.98012, batch time 2.423
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 1, iter 1000, loss 7.18959, smoothed loss 7.52933, grad norm 6.95367, param norm 52.04483, batch time 2.448
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 1, Iter 1000, dev loss: 7.047887
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 24.12 seconds
Epoch 1, Iter 1000, Train F1 score: 0.189684, Train EM score: 0.106000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 166.47 seconds
Epoch 1, Iter 1000, Dev F1 score: 0.195245, Dev EM score: 0.104042
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 1, iter 1100, loss 7.04466, smoothed loss 7.37260, grad norm 6.81580, param norm 52.10847, batch time 2.225
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 1, iter 1200, loss 6.90932, smoothed loss 7.31651, grad norm 6.11674, param norm 52.16269, batch time 2.318
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 1, iter 1300, loss 7.05920, smoothed loss 7.17431, grad norm 6.87241, param norm 52.22692, batch time 2.326
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 1, iter 1400, loss 7.10118, smoothed loss 7.15438, grad norm 6.84704, param norm 52.28679, batch time 2.128
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 1. Time for epoch: 3786.364117
epoch 2, iter 1500, loss 7.07055, smoothed loss 7.07095, grad norm 7.09111, param norm 52.34505, batch time 2.184
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 2, iter 1600, loss 6.71506, smoothed loss 7.00119, grad norm 6.96940, param norm 52.40784, batch time 2.234
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 2, iter 1700, loss 6.65810, smoothed loss 6.95396, grad norm 6.62545, param norm 52.46901, batch time 2.406
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 2, iter 1800, loss 6.66444, smoothed loss 6.90584, grad norm 10.06398, param norm 52.53513, batch time 2.240
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 2, iter 1900, loss 6.94000, smoothed loss 6.86543, grad norm 6.05270, param norm 52.59445, batch time 2.281
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 2, iter 2000, loss 6.96779, smoothed loss 6.78256, grad norm 6.79766, param norm 52.65889, batch time 2.297
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 2, Iter 2000, dev loss: 6.319508
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 24.00 seconds
Epoch 2, Iter 2000, Train F1 score: 0.288738, Train EM score: 0.168000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.96 seconds
Epoch 2, Iter 2000, Dev F1 score: 0.276253, Dev EM score: 0.156978
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 2, iter 2100, loss 6.39705, smoothed loss 6.69851, grad norm 6.78511, param norm 52.72474, batch time 2.206
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 2, iter 2200, loss 5.69829, smoothed loss 6.60672, grad norm 7.35299, param norm 52.79141, batch time 2.270
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 2, iter 2300, loss 6.42031, smoothed loss 6.62388, grad norm 8.12687, param norm 52.85413, batch time 2.289
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 2, iter 2400, loss 7.18872, smoothed loss 6.57228, grad norm 8.37551, param norm 52.91808, batch time 2.209
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 2, iter 2500, loss 7.20061, smoothed loss 6.54077, grad norm 7.21419, param norm 52.98436, batch time 2.265
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 2, iter 2600, loss 6.31991, smoothed loss 6.42236, grad norm 8.83439, param norm 53.04808, batch time 2.256
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 2, iter 2700, loss 6.19455, smoothed loss 6.39635, grad norm 8.19525, param norm 53.11042, batch time 2.085
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 2, iter 2800, loss 6.35743, smoothed loss 6.37817, grad norm 9.22635, param norm 53.17522, batch time 2.274
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 2. Time for epoch: 3753.422176
epoch 3, iter 2900, loss 5.60554, smoothed loss 6.31935, grad norm 7.60161, param norm 53.24707, batch time 2.348
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 3, iter 3000, loss 6.79900, smoothed loss 6.28041, grad norm 8.03536, param norm 53.31010, batch time 2.273
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 3, Iter 3000, dev loss: 5.825120
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.38 seconds
Epoch 3, Iter 3000, Train F1 score: 0.356002, Train EM score: 0.242000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.88 seconds
Epoch 3, Iter 3000, Dev F1 score: 0.327083, Dev EM score: 0.206064
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 3, iter 3100, loss 6.07194, smoothed loss 6.24895, grad norm 7.56408, param norm 53.37165, batch time 2.301
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 3, iter 3200, loss 5.03658, smoothed loss 6.19403, grad norm 7.73645, param norm 53.44081, batch time 2.169
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 3, iter 3300, loss 6.31943, smoothed loss 6.17498, grad norm 7.23571, param norm 53.50233, batch time 2.416
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 3, iter 3400, loss 5.79172, smoothed loss 6.12230, grad norm 8.18906, param norm 53.56562, batch time 2.315
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 3, iter 3500, loss 6.85502, smoothed loss 6.10516, grad norm 8.30382, param norm 53.63219, batch time 2.214
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 3, iter 3600, loss 5.77393, smoothed loss 5.99742, grad norm 8.87073, param norm 53.69588, batch time 2.530
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 3, iter 3700, loss 6.20276, smoothed loss 5.99564, grad norm 8.22383, param norm 53.75520, batch time 2.661
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 3, iter 3800, loss 5.89659, smoothed loss 5.94002, grad norm 7.94284, param norm 53.82418, batch time 2.451
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 3, iter 3900, loss 5.81979, smoothed loss 5.89690, grad norm 7.64572, param norm 53.89094, batch time 2.147
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 3, iter 4000, loss 5.90165, smoothed loss 5.94120, grad norm 10.37013, param norm 53.96289, batch time 2.125
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 3, Iter 4000, dev loss: 5.489823
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.89 seconds
Epoch 3, Iter 4000, Train F1 score: 0.390326, Train EM score: 0.263000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 165.00 seconds
Epoch 3, Iter 4000, Dev F1 score: 0.361161, Dev EM score: 0.235804
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 3, iter 4100, loss 5.46335, smoothed loss 5.82373, grad norm 8.73419, param norm 54.02579, batch time 2.416
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 3, iter 4200, loss 5.49450, smoothed loss 5.79317, grad norm 9.71494, param norm 54.09856, batch time 2.422
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 3, iter 4300, loss 6.20943, smoothed loss 5.75672, grad norm 8.39439, param norm 54.16891, batch time 2.347
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 3. Time for epoch: 4085.229201
epoch 4, iter 4400, loss 5.64215, smoothed loss 5.72048, grad norm 9.76702, param norm 54.24079, batch time 2.230
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 4, iter 4500, loss 5.52552, smoothed loss 5.65074, grad norm 7.06386, param norm 54.30344, batch time 2.163
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 4, iter 4600, loss 5.81383, smoothed loss 5.60286, grad norm 10.02088, param norm 54.36570, batch time 2.320
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 4, iter 4700, loss 5.64699, smoothed loss 5.60541, grad norm 8.64142, param norm 54.43482, batch time 2.159
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 4, iter 4800, loss 5.25411, smoothed loss 5.50989, grad norm 9.28201, param norm 54.49915, batch time 2.138
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 4, iter 4900, loss 5.04940, smoothed loss 5.47220, grad norm 7.26079, param norm 54.56901, batch time 2.287
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 4, iter 5000, loss 5.52901, smoothed loss 5.37430, grad norm 8.12292, param norm 54.63653, batch time 2.426
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 4, Iter 5000, dev loss: 4.842763
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.07 seconds
Epoch 4, Iter 5000, Train F1 score: 0.483375, Train EM score: 0.337000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 165.29 seconds
Epoch 4, Iter 5000, Dev F1 score: 0.445793, Dev EM score: 0.303369
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 4, iter 5100, loss 5.53556, smoothed loss 5.32494, grad norm 7.62739, param norm 54.70406, batch time 2.111
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 4, iter 5200, loss 5.05775, smoothed loss 5.31034, grad norm 7.42279, param norm 54.77432, batch time 2.222
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 4, iter 5300, loss 5.56063, smoothed loss 5.30659, grad norm 6.82333, param norm 54.84301, batch time 2.097
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 4, iter 5400, loss 4.48115, smoothed loss 5.23720, grad norm 7.85085, param norm 54.90883, batch time 2.236
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 4, iter 5500, loss 4.90752, smoothed loss 5.21819, grad norm 7.76635, param norm 54.97923, batch time 2.156
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 4, iter 5600, loss 4.30474, smoothed loss 5.12919, grad norm 7.47115, param norm 55.03685, batch time 2.301
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 4, iter 5700, loss 4.86472, smoothed loss 5.10928, grad norm 7.63298, param norm 55.10471, batch time 2.159
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 4. Time for epoch: 3753.648226
epoch 5, iter 5800, loss 4.31514, smoothed loss 5.07277, grad norm 7.38395, param norm 55.16752, batch time 2.237
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 5, iter 5900, loss 5.45095, smoothed loss 5.08904, grad norm 9.80345, param norm 55.22852, batch time 2.262
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 5, iter 6000, loss 4.84460, smoothed loss 5.02185, grad norm 7.21436, param norm 55.28918, batch time 2.466
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 5, Iter 6000, dev loss: 4.448095
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.44 seconds
Epoch 5, Iter 6000, Train F1 score: 0.537185, Train EM score: 0.384000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.64 seconds
Epoch 5, Iter 6000, Dev F1 score: 0.492190, Dev EM score: 0.344370
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 5, iter 6100, loss 4.75054, smoothed loss 5.00173, grad norm 7.38303, param norm 55.34619, batch time 2.258
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 5, iter 6200, loss 6.04402, smoothed loss 4.97139, grad norm 8.30882, param norm 55.40530, batch time 2.439
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 5, iter 6300, loss 5.57300, smoothed loss 4.94855, grad norm 7.04916, param norm 55.47292, batch time 2.402
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 5, iter 6400, loss 4.16506, smoothed loss 4.88226, grad norm 7.01623, param norm 55.52955, batch time 2.249
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 5, iter 6500, loss 3.87772, smoothed loss 4.84451, grad norm 6.83800, param norm 55.58230, batch time 2.212
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 5, iter 6600, loss 5.47229, smoothed loss 4.83917, grad norm 6.92629, param norm 55.64114, batch time 2.348
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 5, iter 6700, loss 4.54959, smoothed loss 4.79491, grad norm 7.09827, param norm 55.70855, batch time 2.228
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 5, iter 6800, loss 5.53485, smoothed loss 4.78343, grad norm 8.74172, param norm 55.77290, batch time 2.230
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 5, iter 6900, loss 4.41928, smoothed loss 4.80199, grad norm 6.70070, param norm 55.81883, batch time 2.143
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 5, iter 7000, loss 4.93071, smoothed loss 4.74831, grad norm 7.08766, param norm 55.88273, batch time 2.330
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 5, Iter 7000, dev loss: 4.210329
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.79 seconds
Epoch 5, Iter 7000, Train F1 score: 0.563382, Train EM score: 0.408000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 165.23 seconds
Epoch 5, Iter 7000, Dev F1 score: 0.524097, Dev EM score: 0.367565
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 5, iter 7100, loss 4.87799, smoothed loss 4.71181, grad norm 7.29134, param norm 55.93475, batch time 2.152
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 5. Time for epoch: 4098.197147
epoch 6, iter 7200, loss 5.23475, smoothed loss 4.69723, grad norm 7.39511, param norm 55.99448, batch time 2.557
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 6, iter 7300, loss 6.08092, smoothed loss 4.71965, grad norm 8.05801, param norm 56.05020, batch time 2.168
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 6, iter 7400, loss 4.67079, smoothed loss 4.67514, grad norm 7.13404, param norm 56.10506, batch time 2.307
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 6, iter 7500, loss 3.96066, smoothed loss 4.64783, grad norm 6.47856, param norm 56.16156, batch time 2.093
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 6, iter 7600, loss 5.18261, smoothed loss 4.64816, grad norm 7.37110, param norm 56.22027, batch time 2.095
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 6, iter 7700, loss 4.52825, smoothed loss 4.63413, grad norm 7.41284, param norm 56.28083, batch time 2.048
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 6, iter 7800, loss 4.90867, smoothed loss 4.61769, grad norm 7.08055, param norm 56.33494, batch time 2.140
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 6, iter 7900, loss 4.85266, smoothed loss 4.53051, grad norm 7.33302, param norm 56.38111, batch time 2.157
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 6, iter 8000, loss 4.75249, smoothed loss 4.52805, grad norm 8.43098, param norm 56.42780, batch time 2.251
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 6, Iter 8000, dev loss: 4.021979
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.22 seconds
Epoch 6, Iter 8000, Train F1 score: 0.584798, Train EM score: 0.408000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.19 seconds
Epoch 6, Iter 8000, Dev F1 score: 0.552124, Dev EM score: 0.392685
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 6, iter 8100, loss 4.58962, smoothed loss 4.53658, grad norm 6.66175, param norm 56.48312, batch time 2.313
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 6, iter 8200, loss 5.19218, smoothed loss 4.53710, grad norm 7.43822, param norm 56.53888, batch time 2.301
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 6, iter 8300, loss 4.29886, smoothed loss 4.51308, grad norm 8.64831, param norm 56.58751, batch time 2.372
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 6, iter 8400, loss 4.63607, smoothed loss 4.48674, grad norm 6.99825, param norm 56.64524, batch time 2.438
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 6, iter 8500, loss 4.29218, smoothed loss 4.51717, grad norm 6.48386, param norm 56.69372, batch time 2.174
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 6, iter 8600, loss 3.95330, smoothed loss 4.49336, grad norm 6.23405, param norm 56.74145, batch time 2.252
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 6. Time for epoch: 3751.195698
epoch 7, iter 8700, loss 4.06167, smoothed loss 4.46923, grad norm 7.08476, param norm 56.79768, batch time 2.237
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 7, iter 8800, loss 4.18525, smoothed loss 4.44410, grad norm 7.90183, param norm 56.85143, batch time 2.472
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 7, iter 8900, loss 4.43180, smoothed loss 4.45525, grad norm 6.67918, param norm 56.90343, batch time 2.276
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 7, iter 9000, loss 3.65024, smoothed loss 4.44572, grad norm 6.75998, param norm 56.95972, batch time 2.231
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 7, Iter 9000, dev loss: 3.889488
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.79 seconds
Epoch 7, Iter 9000, Train F1 score: 0.603438, Train EM score: 0.439000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 163.70 seconds
Epoch 7, Iter 9000, Dev F1 score: 0.565932, Dev EM score: 0.406737
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 7, iter 9100, loss 4.17613, smoothed loss 4.39319, grad norm 7.54999, param norm 57.01591, batch time 2.259
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 7, iter 9200, loss 4.11864, smoothed loss 4.38832, grad norm 7.28666, param norm 57.07193, batch time 2.278
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 7, iter 9300, loss 5.01627, smoothed loss 4.32185, grad norm 7.97725, param norm 57.12066, batch time 2.467
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 7, iter 9400, loss 4.22176, smoothed loss 4.28741, grad norm 6.40335, param norm 57.16088, batch time 2.200
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 7, iter 9500, loss 4.52570, smoothed loss 4.28779, grad norm 6.63618, param norm 57.21592, batch time 2.305
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 7, iter 9600, loss 4.28714, smoothed loss 4.33118, grad norm 6.88139, param norm 57.25854, batch time 2.260
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 7, iter 9700, loss 4.24124, smoothed loss 4.33357, grad norm 6.29742, param norm 57.31524, batch time 2.300
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 7, iter 9800, loss 3.97077, smoothed loss 4.30513, grad norm 6.25417, param norm 57.36668, batch time 2.221
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 7, iter 9900, loss 3.90002, smoothed loss 4.29858, grad norm 6.68756, param norm 57.41670, batch time 2.244
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 7, iter 10000, loss 3.87088, smoothed loss 4.30347, grad norm 6.70557, param norm 57.46695, batch time 2.225
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 7, Iter 10000, dev loss: 3.785987
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.99 seconds
Epoch 7, Iter 10000, Train F1 score: 0.599722, Train EM score: 0.440000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.51 seconds
Epoch 7, Iter 10000, Dev F1 score: 0.580068, Dev EM score: 0.420500
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
End of epoch 7. Time for epoch: 4098.365442
epoch 8, iter 10100, loss 4.42373, smoothed loss 4.32785, grad norm 6.87984, param norm 57.51279, batch time 2.390
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 8, iter 10200, loss 3.74831, smoothed loss 4.26994, grad norm 7.44776, param norm 57.56949, batch time 2.279
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 8, iter 10300, loss 4.12335, smoothed loss 4.25994, grad norm 6.71688, param norm 57.62320, batch time 2.140
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 8, iter 10400, loss 3.80024, smoothed loss 4.23859, grad norm 6.34461, param norm 57.67617, batch time 2.201
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 8, iter 10500, loss 4.07422, smoothed loss 4.22371, grad norm 6.42186, param norm 57.72615, batch time 2.308
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 8, iter 10600, loss 3.67515, smoothed loss 4.22366, grad norm 6.55226, param norm 57.77758, batch time 2.366
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 8, iter 10700, loss 4.35592, smoothed loss 4.18835, grad norm 7.36971, param norm 57.82968, batch time 2.098
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 8, iter 10800, loss 3.99249, smoothed loss 4.14345, grad norm 7.26313, param norm 57.88293, batch time 2.295
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 8, iter 10900, loss 4.56122, smoothed loss 4.13880, grad norm 7.55206, param norm 57.92705, batch time 2.445
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 8, iter 11000, loss 3.85627, smoothed loss 4.15680, grad norm 7.11156, param norm 57.97887, batch time 2.342
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 8, Iter 11000, dev loss: 3.707877
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.25 seconds
Epoch 8, Iter 11000, Train F1 score: 0.597103, Train EM score: 0.440000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 165.75 seconds
Epoch 8, Iter 11000, Dev F1 score: 0.585796, Dev EM score: 0.427334
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 8, iter 11100, loss 4.45108, smoothed loss 4.16279, grad norm 6.51035, param norm 58.03035, batch time 2.101
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 8, iter 11200, loss 4.28180, smoothed loss 4.13462, grad norm 6.76424, param norm 58.08391, batch time 2.152
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 8, iter 11300, loss 4.03541, smoothed loss 4.12786, grad norm 7.16752, param norm 58.13480, batch time 2.286
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 8, iter 11400, loss 4.60332, smoothed loss 4.15948, grad norm 7.27044, param norm 58.18401, batch time 2.315
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 8. Time for epoch: 3753.744163
epoch 9, iter 11500, loss 4.92768, smoothed loss 4.16783, grad norm 7.92028, param norm 58.22733, batch time 2.144
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 9, iter 11600, loss 4.31355, smoothed loss 4.14743, grad norm 7.21238, param norm 58.28526, batch time 2.175
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 9, iter 11700, loss 4.13698, smoothed loss 4.18035, grad norm 6.81964, param norm 58.33196, batch time 2.355
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 9, iter 11800, loss 4.00802, smoothed loss 4.10990, grad norm 6.78967, param norm 58.38640, batch time 2.260
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 9, iter 11900, loss 3.71161, smoothed loss 4.12993, grad norm 6.57970, param norm 58.43818, batch time 2.532
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 9, iter 12000, loss 4.24990, smoothed loss 4.07010, grad norm 6.72803, param norm 58.48791, batch time 2.211
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 9, Iter 12000, dev loss: 3.658751
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.19 seconds
Epoch 9, Iter 12000, Train F1 score: 0.620341, Train EM score: 0.464000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 165.09 seconds
Epoch 9, Iter 12000, Dev F1 score: 0.592592, Dev EM score: 0.433013
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 9, iter 12100, loss 4.00393, smoothed loss 4.04825, grad norm 6.71430, param norm 58.53867, batch time 2.165
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 9, iter 12200, loss 5.01656, smoothed loss 4.03954, grad norm 7.28382, param norm 58.58684, batch time 2.204
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 9, iter 12300, loss 3.55180, smoothed loss 4.03333, grad norm 6.11389, param norm 58.63076, batch time 2.523
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 9, iter 12400, loss 4.40103, smoothed loss 4.03908, grad norm 6.29087, param norm 58.67870, batch time 2.289
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 9, iter 12500, loss 4.79788, smoothed loss 4.06357, grad norm 6.72657, param norm 58.72393, batch time 2.374
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 9, iter 12600, loss 2.93474, smoothed loss 4.06207, grad norm 6.28194, param norm 58.76772, batch time 2.298
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 9, iter 12700, loss 4.30343, smoothed loss 4.00855, grad norm 6.91088, param norm 58.81715, batch time 2.157
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 9, iter 12800, loss 4.82182, smoothed loss 4.02491, grad norm 6.90279, param norm 58.86390, batch time 2.156
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 9, iter 12900, loss 4.46253, smoothed loss 4.02161, grad norm 7.41558, param norm 58.91136, batch time 2.224
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 9. Time for epoch: 3751.133924
epoch 10, iter 13000, loss 3.50259, smoothed loss 4.07400, grad norm 5.79657, param norm 58.96584, batch time 2.117
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 10, Iter 13000, dev loss: 3.611443
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.36 seconds
Epoch 10, Iter 13000, Train F1 score: 0.643874, Train EM score: 0.493000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.45 seconds
Epoch 10, Iter 13000, Dev F1 score: 0.595482, Dev EM score: 0.434745
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 10, iter 13100, loss 3.92261, smoothed loss 4.00680, grad norm 6.97651, param norm 59.01299, batch time 2.380
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 10, iter 13200, loss 3.78779, smoothed loss 4.02413, grad norm 6.91262, param norm 59.05947, batch time 2.470
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 10, iter 13300, loss 4.79487, smoothed loss 4.04224, grad norm 6.92636, param norm 59.10762, batch time 2.505
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 10, iter 13400, loss 3.76487, smoothed loss 3.99015, grad norm 6.17362, param norm 59.16010, batch time 2.286
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 10, iter 13500, loss 4.56909, smoothed loss 3.96083, grad norm 7.99679, param norm 59.21317, batch time 2.305
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 10, iter 13600, loss 3.64179, smoothed loss 3.88603, grad norm 7.18065, param norm 59.26472, batch time 2.216
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 10, iter 13700, loss 4.04701, smoothed loss 3.92952, grad norm 7.21401, param norm 59.30335, batch time 2.205
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 10, iter 13800, loss 3.24348, smoothed loss 3.97558, grad norm 6.51652, param norm 59.35179, batch time 2.115
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 10, iter 13900, loss 4.42037, smoothed loss 3.92676, grad norm 6.53502, param norm 59.40049, batch time 2.497
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 10, iter 14000, loss 5.09902, smoothed loss 3.97422, grad norm 7.19672, param norm 59.44928, batch time 2.404
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 10, Iter 14000, dev loss: 3.564681
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.51 seconds
Epoch 10, Iter 14000, Train F1 score: 0.644302, Train EM score: 0.491000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 165.22 seconds
Epoch 10, Iter 14000, Dev F1 score: 0.605084, Dev EM score: 0.441771
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 10, iter 14100, loss 3.90433, smoothed loss 3.90991, grad norm 7.13983, param norm 59.49940, batch time 2.380
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 10, iter 14200, loss 3.76116, smoothed loss 3.91715, grad norm 6.30527, param norm 59.54183, batch time 2.295
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 10, iter 14300, loss 3.77748, smoothed loss 3.92165, grad norm 6.60854, param norm 59.59098, batch time 2.171
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 10. Time for epoch: 4101.930651
epoch 11, iter 14400, loss 3.51824, smoothed loss 3.90856, grad norm 5.95664, param norm 59.64297, batch time 2.345
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 11, iter 14500, loss 3.59741, smoothed loss 3.91895, grad norm 6.30507, param norm 59.69349, batch time 2.567
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 11, iter 14600, loss 3.85922, smoothed loss 3.92555, grad norm 6.48347, param norm 59.73723, batch time 2.174
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 11, iter 14700, loss 3.84529, smoothed loss 3.88994, grad norm 6.52634, param norm 59.78950, batch time 2.413
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 11, iter 14800, loss 4.38199, smoothed loss 3.89154, grad norm 7.52971, param norm 59.83609, batch time 2.315
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 11, iter 14900, loss 3.42448, smoothed loss 3.82101, grad norm 6.12270, param norm 59.88879, batch time 2.213
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 11, iter 15000, loss 3.47655, smoothed loss 3.85673, grad norm 6.24725, param norm 59.93327, batch time 2.229
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 11, Iter 15000, dev loss: 3.493022
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.53 seconds
Epoch 11, Iter 15000, Train F1 score: 0.675184, Train EM score: 0.526000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.38 seconds
Epoch 11, Iter 15000, Dev F1 score: 0.610941, Dev EM score: 0.446679
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 11, iter 15100, loss 3.61497, smoothed loss 3.84815, grad norm 5.99442, param norm 59.97496, batch time 2.272
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 11, iter 15200, loss 4.02661, smoothed loss 3.84000, grad norm 5.92284, param norm 60.02094, batch time 2.280
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 11, iter 15300, loss 3.25385, smoothed loss 3.82861, grad norm 5.90155, param norm 60.07310, batch time 2.176
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 11, iter 15400, loss 3.64996, smoothed loss 3.87254, grad norm 5.86921, param norm 60.11049, batch time 2.214
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 11, iter 15500, loss 3.43523, smoothed loss 3.86747, grad norm 5.78584, param norm 60.16241, batch time 2.389
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 11, iter 15600, loss 4.67603, smoothed loss 3.84557, grad norm 6.88291, param norm 60.20835, batch time 2.332
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 11, iter 15700, loss 3.73703, smoothed loss 3.83022, grad norm 6.19067, param norm 60.25530, batch time 2.327
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 11. Time for epoch: 3755.137847
epoch 12, iter 15800, loss 3.83680, smoothed loss 3.88128, grad norm 6.47433, param norm 60.30020, batch time 2.370
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 12, iter 15900, loss 3.16559, smoothed loss 3.78594, grad norm 5.35365, param norm 60.34776, batch time 2.244
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 12, iter 16000, loss 3.57076, smoothed loss 3.86899, grad norm 6.45868, param norm 60.39309, batch time 2.288
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 12, Iter 16000, dev loss: 3.442755
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 24.33 seconds
Epoch 12, Iter 16000, Train F1 score: 0.663102, Train EM score: 0.515000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.64 seconds
Epoch 12, Iter 16000, Dev F1 score: 0.614752, Dev EM score: 0.453032
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 12, iter 16100, loss 3.33163, smoothed loss 3.79877, grad norm 6.15591, param norm 60.43654, batch time 2.347
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 12, iter 16200, loss 4.19096, smoothed loss 3.79067, grad norm 6.90908, param norm 60.48303, batch time 2.209
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 12, iter 16300, loss 3.69835, smoothed loss 3.84836, grad norm 6.20179, param norm 60.52927, batch time 2.282
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 12, iter 16400, loss 3.38381, smoothed loss 3.78941, grad norm 5.72974, param norm 60.57797, batch time 2.142
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 12, iter 16500, loss 4.02032, smoothed loss 3.80301, grad norm 6.34993, param norm 60.61747, batch time 2.383
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 12, iter 16600, loss 4.44670, smoothed loss 3.77107, grad norm 6.93772, param norm 60.65890, batch time 2.194
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 12, iter 16700, loss 4.05937, smoothed loss 3.77316, grad norm 6.58715, param norm 60.71111, batch time 2.243
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 12, iter 16800, loss 3.70537, smoothed loss 3.80959, grad norm 6.07532, param norm 60.75601, batch time 2.225
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 12, iter 16900, loss 3.12948, smoothed loss 3.77660, grad norm 5.87304, param norm 60.79956, batch time 2.298
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 12, iter 17000, loss 3.50538, smoothed loss 3.76568, grad norm 6.06183, param norm 60.84839, batch time 2.162
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 12, Iter 17000, dev loss: 3.420812
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.92 seconds
Epoch 12, Iter 17000, Train F1 score: 0.662755, Train EM score: 0.504000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.95 seconds
Epoch 12, Iter 17000, Dev F1 score: 0.617256, Dev EM score: 0.458710
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 12, iter 17100, loss 3.75451, smoothed loss 3.76302, grad norm 6.37141, param norm 60.88875, batch time 2.572
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 12, iter 17200, loss 2.91148, smoothed loss 3.76743, grad norm 5.44717, param norm 60.93861, batch time 2.448
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 12. Time for epoch: 4093.377653
epoch 13, iter 17300, loss 3.56288, smoothed loss 3.75010, grad norm 6.08184, param norm 60.99469, batch time 2.263
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 13, iter 17400, loss 3.85791, smoothed loss 3.76759, grad norm 6.38696, param norm 61.04023, batch time 2.254
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 13, iter 17500, loss 3.13246, smoothed loss 3.76447, grad norm 5.72177, param norm 61.08490, batch time 2.170
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 13, iter 17600, loss 3.85251, smoothed loss 3.74744, grad norm 7.27052, param norm 61.12917, batch time 2.235
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 13, iter 17700, loss 3.38235, smoothed loss 3.72385, grad norm 5.97019, param norm 61.17991, batch time 2.235
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 13, iter 17800, loss 4.04220, smoothed loss 3.72712, grad norm 6.75102, param norm 61.22752, batch time 2.402
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 13, iter 17900, loss 3.48517, smoothed loss 3.68088, grad norm 6.33636, param norm 61.27642, batch time 2.186
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 13, iter 18000, loss 3.87452, smoothed loss 3.69117, grad norm 6.51915, param norm 61.31460, batch time 2.356
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 13, Iter 18000, dev loss: 3.396190
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.28 seconds
Epoch 13, Iter 18000, Train F1 score: 0.670145, Train EM score: 0.522000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 163.13 seconds
Epoch 13, Iter 18000, Dev F1 score: 0.622166, Dev EM score: 0.461694
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 13, iter 18100, loss 3.81167, smoothed loss 3.69207, grad norm 7.20475, param norm 61.35464, batch time 2.185
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 13, iter 18200, loss 3.57078, smoothed loss 3.69522, grad norm 7.01178, param norm 61.39875, batch time 2.137
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 13, iter 18300, loss 3.98045, smoothed loss 3.70548, grad norm 6.37635, param norm 61.43895, batch time 2.363
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 13, iter 18400, loss 4.36709, smoothed loss 3.63456, grad norm 7.47300, param norm 61.49007, batch time 2.560
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 13, iter 18500, loss 3.96176, smoothed loss 3.65603, grad norm 6.36855, param norm 61.53336, batch time 2.324
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 13, iter 18600, loss 3.41100, smoothed loss 3.70694, grad norm 6.03170, param norm 61.56813, batch time 2.292
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 13. Time for epoch: 3755.599620
epoch 14, iter 18700, loss 3.60118, smoothed loss 3.69938, grad norm 6.45131, param norm 61.61628, batch time 2.340
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 14, iter 18800, loss 3.49865, smoothed loss 3.65878, grad norm 6.54056, param norm 61.67379, batch time 2.249
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 14, iter 18900, loss 3.07264, smoothed loss 3.68674, grad norm 6.61152, param norm 61.71645, batch time 2.434
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 14, iter 19000, loss 3.78056, smoothed loss 3.67210, grad norm 6.57005, param norm 61.76292, batch time 2.134
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 14, Iter 19000, dev loss: 3.352202
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.40 seconds
Epoch 14, Iter 19000, Train F1 score: 0.660461, Train EM score: 0.517000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 162.56 seconds
Epoch 14, Iter 19000, Dev F1 score: 0.625728, Dev EM score: 0.466025
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 14, iter 19100, loss 3.38984, smoothed loss 3.66523, grad norm 5.52172, param norm 61.80627, batch time 2.503
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 14, iter 19200, loss 3.01645, smoothed loss 3.64061, grad norm 6.09418, param norm 61.85291, batch time 2.369
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 14, iter 19300, loss 3.38640, smoothed loss 3.63934, grad norm 6.80747, param norm 61.89615, batch time 2.171
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 14, iter 19400, loss 3.78448, smoothed loss 3.63121, grad norm 6.44405, param norm 61.93972, batch time 2.318
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 14, iter 19500, loss 3.94813, smoothed loss 3.61135, grad norm 6.29456, param norm 61.98212, batch time 2.263
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 14, iter 19600, loss 3.35831, smoothed loss 3.61098, grad norm 5.63487, param norm 62.02954, batch time 2.254
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 14, iter 19700, loss 3.16682, smoothed loss 3.62959, grad norm 6.37188, param norm 62.06748, batch time 2.318
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 14, iter 19800, loss 3.31736, smoothed loss 3.61463, grad norm 6.10792, param norm 62.11744, batch time 2.066
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 14, iter 19900, loss 3.72235, smoothed loss 3.61282, grad norm 6.70737, param norm 62.15680, batch time 2.391
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 14, iter 20000, loss 3.58926, smoothed loss 3.60325, grad norm 6.19630, param norm 62.20038, batch time 2.088
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 14, Iter 20000, dev loss: 3.357894
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.66 seconds
Epoch 14, Iter 20000, Train F1 score: 0.680428, Train EM score: 0.521000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 162.28 seconds
Epoch 14, Iter 20000, Dev F1 score: 0.631321, Dev EM score: 0.471992
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
End of epoch 14. Time for epoch: 4093.187896
epoch 15, iter 20100, loss 3.05670, smoothed loss 3.62794, grad norm 5.87203, param norm 62.24847, batch time 2.382
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 15, iter 20200, loss 4.11138, smoothed loss 3.65859, grad norm 6.17948, param norm 62.29599, batch time 2.236
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 15, iter 20300, loss 3.04809, smoothed loss 3.55598, grad norm 6.40743, param norm 62.34114, batch time 2.316
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 15, iter 20400, loss 3.10421, smoothed loss 3.63280, grad norm 5.87740, param norm 62.37962, batch time 2.073
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 15, iter 20500, loss 3.46379, smoothed loss 3.61975, grad norm 5.88704, param norm 62.42406, batch time 2.249
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 15, iter 20600, loss 3.97725, smoothed loss 3.59944, grad norm 6.78904, param norm 62.46465, batch time 2.115
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 15, iter 20700, loss 2.98873, smoothed loss 3.58350, grad norm 5.58587, param norm 62.51020, batch time 2.449
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 15, iter 20800, loss 3.13829, smoothed loss 3.57874, grad norm 6.31221, param norm 62.55253, batch time 2.420
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 15, iter 20900, loss 3.07670, smoothed loss 3.57672, grad norm 5.70766, param norm 62.59264, batch time 2.381
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 15, iter 21000, loss 3.75892, smoothed loss 3.57240, grad norm 5.76535, param norm 62.63673, batch time 2.276
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 15, Iter 21000, dev loss: 3.333366
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.85 seconds
Epoch 15, Iter 21000, Train F1 score: 0.675755, Train EM score: 0.524000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.63 seconds
Epoch 15, Iter 21000, Dev F1 score: 0.632507, Dev EM score: 0.470067
epoch 15, iter 21100, loss 3.64589, smoothed loss 3.57449, grad norm 6.34486, param norm 62.68024, batch time 2.431
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 15, iter 21200, loss 4.34871, smoothed loss 3.59693, grad norm 8.15482, param norm 62.72481, batch time 2.204
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 15, iter 21300, loss 3.48552, smoothed loss 3.56160, grad norm 6.27316, param norm 62.76655, batch time 2.249
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 15, iter 21400, loss 3.75696, smoothed loss 3.53291, grad norm 6.84858, param norm 62.80851, batch time 2.300
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 15, iter 21500, loss 3.88599, smoothed loss 3.56531, grad norm 6.00245, param norm 62.85237, batch time 2.250
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 15. Time for epoch: 3748.955409
epoch 16, iter 21600, loss 3.53484, smoothed loss 3.57058, grad norm 6.71871, param norm 62.89386, batch time 2.189
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 16, iter 21700, loss 3.91496, smoothed loss 3.55841, grad norm 6.48333, param norm 62.93873, batch time 2.108
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 16, iter 21800, loss 3.77294, smoothed loss 3.60643, grad norm 6.33590, param norm 62.98046, batch time 2.209
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 16, iter 21900, loss 3.88279, smoothed loss 3.54078, grad norm 6.70780, param norm 63.02803, batch time 2.135
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 16, iter 22000, loss 3.51561, smoothed loss 3.57698, grad norm 6.17556, param norm 63.06648, batch time 2.270
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 16, Iter 22000, dev loss: 3.284418
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.66 seconds
Epoch 16, Iter 22000, Train F1 score: 0.681883, Train EM score: 0.529000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.87 seconds
Epoch 16, Iter 22000, Dev F1 score: 0.636640, Dev EM score: 0.477767
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 16, iter 22100, loss 3.48841, smoothed loss 3.58332, grad norm 6.82113, param norm 63.11426, batch time 2.625
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 16, iter 22200, loss 3.75790, smoothed loss 3.51418, grad norm 7.52606, param norm 63.15528, batch time 2.098
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 16, iter 22300, loss 3.14540, smoothed loss 3.48034, grad norm 6.27118, param norm 63.18827, batch time 2.267
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 16, iter 22400, loss 3.48206, smoothed loss 3.49713, grad norm 6.51131, param norm 63.23280, batch time 2.334
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 16, iter 22500, loss 3.35757, smoothed loss 3.50302, grad norm 5.86182, param norm 63.27316, batch time 2.267
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 16, iter 22600, loss 4.13511, smoothed loss 3.52015, grad norm 9.02604, param norm 63.31077, batch time 2.109
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 16, iter 22700, loss 3.24574, smoothed loss 3.51333, grad norm 5.71305, param norm 63.35508, batch time 2.215
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 16, iter 22800, loss 3.54204, smoothed loss 3.46773, grad norm 7.00773, param norm 63.39946, batch time 2.221
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 16, iter 22900, loss 3.50964, smoothed loss 3.54297, grad norm 6.00180, param norm 63.43510, batch time 2.448
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 16. Time for epoch: 3753.214367
epoch 17, iter 23000, loss 3.43208, smoothed loss 3.49049, grad norm 6.37604, param norm 63.47373, batch time 2.184
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 17, Iter 23000, dev loss: 3.260289
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.41 seconds
Epoch 17, Iter 23000, Train F1 score: 0.699170, Train EM score: 0.545000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.39 seconds
Epoch 17, Iter 23000, Dev F1 score: 0.638382, Dev EM score: 0.479692
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 17, iter 23100, loss 3.35157, smoothed loss 3.51245, grad norm 5.78454, param norm 63.52220, batch time 2.198
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 17, iter 23200, loss 4.30773, smoothed loss 3.51647, grad norm 6.88309, param norm 63.57243, batch time 2.155
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 17, iter 23300, loss 3.60039, smoothed loss 3.51684, grad norm 6.42789, param norm 63.61366, batch time 2.348
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 17, iter 23400, loss 2.52463, smoothed loss 3.46354, grad norm 5.07236, param norm 63.65576, batch time 2.464
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 17, iter 23500, loss 3.53965, smoothed loss 3.48531, grad norm 6.98960, param norm 63.69900, batch time 2.239
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 17, iter 23600, loss 3.19278, smoothed loss 3.43860, grad norm 6.31749, param norm 63.74239, batch time 2.349
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 17, iter 23700, loss 3.09291, smoothed loss 3.46164, grad norm 5.50475, param norm 63.78163, batch time 2.153
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 17, iter 23800, loss 2.70813, smoothed loss 3.42759, grad norm 5.95121, param norm 63.82362, batch time 2.287
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 17, iter 23900, loss 3.68833, smoothed loss 3.43406, grad norm 6.02623, param norm 63.86628, batch time 2.162
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 17, iter 24000, loss 4.45063, smoothed loss 3.49016, grad norm 7.56263, param norm 63.90774, batch time 2.340
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 17, Iter 24000, dev loss: 3.243737
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.46 seconds
Epoch 17, Iter 24000, Train F1 score: 0.688479, Train EM score: 0.529000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 165.58 seconds
Epoch 17, Iter 24000, Dev F1 score: 0.642523, Dev EM score: 0.484023
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 17, iter 24100, loss 2.83613, smoothed loss 3.44441, grad norm 5.79182, param norm 63.95042, batch time 2.363
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 17, iter 24200, loss 3.05299, smoothed loss 3.42018, grad norm 5.75855, param norm 63.98989, batch time 2.212
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 17, iter 24300, loss 3.87032, smoothed loss 3.50108, grad norm 6.71749, param norm 64.02724, batch time 2.294
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 17. Time for epoch: 4094.741505
epoch 18, iter 24400, loss 3.60679, smoothed loss 3.50066, grad norm 5.94833, param norm 64.06972, batch time 2.271
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 18, iter 24500, loss 3.98754, smoothed loss 3.46460, grad norm 6.61815, param norm 64.11215, batch time 2.311
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 18, iter 24600, loss 4.30450, smoothed loss 3.44805, grad norm 5.78382, param norm 64.15346, batch time 2.415
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 18, iter 24700, loss 3.36485, smoothed loss 3.47772, grad norm 6.35890, param norm 64.19814, batch time 2.139
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 18, iter 24800, loss 2.71993, smoothed loss 3.42420, grad norm 5.14701, param norm 64.23947, batch time 2.192
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 18, iter 24900, loss 2.88970, smoothed loss 3.45831, grad norm 5.88004, param norm 64.28593, batch time 2.094
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 18, iter 25000, loss 3.37629, smoothed loss 3.45756, grad norm 6.40799, param norm 64.32485, batch time 2.118
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 18, Iter 25000, dev loss: 3.225261
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.66 seconds
Epoch 18, Iter 25000, Train F1 score: 0.706925, Train EM score: 0.559000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.26 seconds
Epoch 18, Iter 25000, Dev F1 score: 0.644543, Dev EM score: 0.485178
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 18, iter 25100, loss 3.38591, smoothed loss 3.40497, grad norm 6.93877, param norm 64.36296, batch time 2.445
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 18, iter 25200, loss 3.34211, smoothed loss 3.43237, grad norm 6.45409, param norm 64.40312, batch time 2.587
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 18, iter 25300, loss 3.11071, smoothed loss 3.42892, grad norm 5.60853, param norm 64.44439, batch time 2.280
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 18, iter 25400, loss 2.53610, smoothed loss 3.42066, grad norm 5.47748, param norm 64.48009, batch time 2.195
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 18, iter 25500, loss 3.65134, smoothed loss 3.45869, grad norm 6.09492, param norm 64.52065, batch time 2.213
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 18, iter 25600, loss 3.82248, smoothed loss 3.41658, grad norm 7.73691, param norm 64.56452, batch time 2.416
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 18, iter 25700, loss 3.64760, smoothed loss 3.41387, grad norm 6.74661, param norm 64.60780, batch time 2.259
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 18, iter 25800, loss 2.91878, smoothed loss 3.43195, grad norm 6.12220, param norm 64.64057, batch time 2.306
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 18. Time for epoch: 3752.954715
epoch 19, iter 25900, loss 3.46475, smoothed loss 3.39892, grad norm 6.23238, param norm 64.68230, batch time 2.178
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 19, iter 26000, loss 3.40351, smoothed loss 3.41020, grad norm 6.11812, param norm 64.72286, batch time 2.351
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 19, Iter 26000, dev loss: 3.221563
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.47 seconds
Epoch 19, Iter 26000, Train F1 score: 0.709549, Train EM score: 0.556000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 163.90 seconds
Epoch 19, Iter 26000, Dev F1 score: 0.641571, Dev EM score: 0.485274
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 19, iter 26100, loss 3.81877, smoothed loss 3.40391, grad norm 6.24951, param norm 64.76682, batch time 2.458
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 19, iter 26200, loss 4.11772, smoothed loss 3.43896, grad norm 6.34669, param norm 64.80935, batch time 2.345
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 19, iter 26300, loss 2.99197, smoothed loss 3.39853, grad norm 6.34114, param norm 64.85185, batch time 2.258
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 19, iter 26400, loss 4.03932, smoothed loss 3.38793, grad norm 7.11868, param norm 64.89610, batch time 2.261
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 19, iter 26500, loss 3.14579, smoothed loss 3.35540, grad norm 5.85329, param norm 64.92531, batch time 2.371
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 19, iter 26600, loss 3.33902, smoothed loss 3.39621, grad norm 6.29645, param norm 64.96607, batch time 2.121
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 19, iter 26700, loss 3.65931, smoothed loss 3.39044, grad norm 6.59452, param norm 65.00609, batch time 2.186
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 19, iter 26800, loss 3.06102, smoothed loss 3.39701, grad norm 6.38504, param norm 65.04760, batch time 2.156
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 19, iter 26900, loss 3.57678, smoothed loss 3.38291, grad norm 6.44926, param norm 65.09142, batch time 2.375
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 19, iter 27000, loss 2.90528, smoothed loss 3.35583, grad norm 5.70516, param norm 65.12513, batch time 2.173
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 19, Iter 27000, dev loss: 3.212598
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 22.95 seconds
Epoch 19, Iter 27000, Train F1 score: 0.726622, Train EM score: 0.591000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.98 seconds
Epoch 19, Iter 27000, Dev F1 score: 0.645930, Dev EM score: 0.489317
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 19, iter 27100, loss 2.92587, smoothed loss 3.35357, grad norm 5.74958, param norm 65.16418, batch time 2.236
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 19, iter 27200, loss 2.55841, smoothed loss 3.37543, grad norm 6.13318, param norm 65.19949, batch time 2.233
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 19. Time for epoch: 4095.107439
epoch 20, iter 27300, loss 3.42821, smoothed loss 3.38617, grad norm 7.47713, param norm 65.24245, batch time 2.096
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 20, iter 27400, loss 3.30506, smoothed loss 3.36839, grad norm 6.01670, param norm 65.28457, batch time 2.311
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 20, iter 27500, loss 3.19776, smoothed loss 3.38394, grad norm 6.87940, param norm 65.32777, batch time 2.363
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 20, iter 27600, loss 2.97595, smoothed loss 3.38875, grad norm 5.51313, param norm 65.36746, batch time 2.126
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 20, iter 27700, loss 3.32720, smoothed loss 3.41217, grad norm 5.74180, param norm 65.40167, batch time 2.123
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 20, iter 27800, loss 2.90004, smoothed loss 3.36610, grad norm 5.81833, param norm 65.44160, batch time 2.083
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 20, iter 27900, loss 3.22083, smoothed loss 3.32544, grad norm 6.16170, param norm 65.48045, batch time 2.242
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 20, iter 28000, loss 3.98795, smoothed loss 3.34003, grad norm 6.01652, param norm 65.51611, batch time 2.229
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 20, Iter 28000, dev loss: 3.185719
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.45 seconds
Epoch 20, Iter 28000, Train F1 score: 0.708698, Train EM score: 0.571000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 166.12 seconds
Epoch 20, Iter 28000, Dev F1 score: 0.645682, Dev EM score: 0.486718
epoch 20, iter 28100, loss 3.60077, smoothed loss 3.32800, grad norm 7.27327, param norm 65.55395, batch time 2.201
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 20, iter 28200, loss 2.48712, smoothed loss 3.34708, grad norm 5.80962, param norm 65.59392, batch time 2.326
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 20, iter 28300, loss 3.21559, smoothed loss 3.34069, grad norm 6.74206, param norm 65.62600, batch time 2.194
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 20, iter 28400, loss 3.48900, smoothed loss 3.39738, grad norm 5.73590, param norm 65.66575, batch time 2.308
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 20, iter 28500, loss 3.78623, smoothed loss 3.31899, grad norm 7.31517, param norm 65.70906, batch time 2.201
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 20, iter 28600, loss 3.38175, smoothed loss 3.34791, grad norm 6.14375, param norm 65.75027, batch time 2.245
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 20, iter 28700, loss 4.03957, smoothed loss 3.37621, grad norm 6.85903, param norm 65.78701, batch time 2.581
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 20. Time for epoch: 3755.749257
epoch 21, iter 28800, loss 3.87231, smoothed loss 3.34906, grad norm 6.55168, param norm 65.82959, batch time 2.549
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 21, iter 28900, loss 3.01167, smoothed loss 3.33838, grad norm 5.52048, param norm 65.87196, batch time 2.284
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 21, iter 29000, loss 3.48462, smoothed loss 3.32477, grad norm 6.39034, param norm 65.91463, batch time 2.189
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 21, Iter 29000, dev loss: 3.173904
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 24.39 seconds
Epoch 21, Iter 29000, Train F1 score: 0.709412, Train EM score: 0.571000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.36 seconds
Epoch 21, Iter 29000, Dev F1 score: 0.648553, Dev EM score: 0.491338
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 21, iter 29100, loss 3.45110, smoothed loss 3.34232, grad norm 6.28256, param norm 65.95027, batch time 2.442
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 21, iter 29200, loss 4.03128, smoothed loss 3.38172, grad norm 6.79250, param norm 65.98887, batch time 2.106
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 21, iter 29300, loss 3.20577, smoothed loss 3.26671, grad norm 5.91156, param norm 66.02769, batch time 2.336
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 21, iter 29400, loss 3.08803, smoothed loss 3.29920, grad norm 5.78148, param norm 66.06603, batch time 2.398
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 21, iter 29500, loss 2.82891, smoothed loss 3.28301, grad norm 6.34007, param norm 66.10555, batch time 2.322
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 21, iter 29600, loss 3.07166, smoothed loss 3.29153, grad norm 7.02748, param norm 66.14767, batch time 2.361
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 21, iter 29700, loss 3.16039, smoothed loss 3.31467, grad norm 6.29279, param norm 66.18320, batch time 2.249
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 21, iter 29800, loss 3.43080, smoothed loss 3.31437, grad norm 6.31703, param norm 66.22007, batch time 2.175
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 21, iter 29900, loss 4.02347, smoothed loss 3.29758, grad norm 7.20202, param norm 66.25883, batch time 2.240
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 21, iter 30000, loss 3.30471, smoothed loss 3.27881, grad norm 5.76398, param norm 66.30470, batch time 2.319
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 21, Iter 30000, dev loss: 3.156839
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.47 seconds
Epoch 21, Iter 30000, Train F1 score: 0.694133, Train EM score: 0.558000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.96 seconds
Epoch 21, Iter 30000, Dev F1 score: 0.653494, Dev EM score: 0.495573
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 21, iter 30100, loss 3.06027, smoothed loss 3.30641, grad norm 6.52202, param norm 66.34377, batch time 2.071
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 21. Time for epoch: 4095.765473
epoch 22, iter 30200, loss 2.79128, smoothed loss 3.30244, grad norm 5.39374, param norm 66.38032, batch time 2.294
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 22, iter 30300, loss 3.13764, smoothed loss 3.29641, grad norm 5.96207, param norm 66.42110, batch time 2.105
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 22, iter 30400, loss 2.90303, smoothed loss 3.31462, grad norm 5.67881, param norm 66.45683, batch time 2.133
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 22, iter 30500, loss 3.16336, smoothed loss 3.29213, grad norm 6.87854, param norm 66.49640, batch time 2.251
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 22, iter 30600, loss 3.12634, smoothed loss 3.28114, grad norm 6.65682, param norm 66.53714, batch time 2.265
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 22, iter 30700, loss 3.94149, smoothed loss 3.27878, grad norm 6.72757, param norm 66.57181, batch time 2.169
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 22, iter 30800, loss 2.57871, smoothed loss 3.23243, grad norm 5.41121, param norm 66.61249, batch time 2.138
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 22, iter 30900, loss 2.57009, smoothed loss 3.27414, grad norm 5.42711, param norm 66.64611, batch time 2.322
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 22, iter 31000, loss 3.00621, smoothed loss 3.25373, grad norm 5.10979, param norm 66.68615, batch time 2.259
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 22, Iter 31000, dev loss: 3.168078
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 24.03 seconds
Epoch 22, Iter 31000, Train F1 score: 0.722785, Train EM score: 0.567000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.03 seconds
Epoch 22, Iter 31000, Dev F1 score: 0.652477, Dev EM score: 0.492204
epoch 22, iter 31100, loss 4.12067, smoothed loss 3.25693, grad norm 6.39809, param norm 66.72507, batch time 2.190
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 22, iter 31200, loss 2.95575, smoothed loss 3.26854, grad norm 6.47533, param norm 66.76212, batch time 2.104
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 22, iter 31300, loss 2.98017, smoothed loss 3.26432, grad norm 6.01706, param norm 66.80000, batch time 2.344
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 22, iter 31400, loss 2.97266, smoothed loss 3.27700, grad norm 6.28055, param norm 66.83399, batch time 2.423
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 22, iter 31500, loss 2.42126, smoothed loss 3.31973, grad norm 5.25212, param norm 66.87157, batch time 2.439
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 22. Time for epoch: 3753.609068
epoch 23, iter 31600, loss 2.78019, smoothed loss 3.25322, grad norm 6.48862, param norm 66.90649, batch time 2.213
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 23, iter 31700, loss 3.04826, smoothed loss 3.25353, grad norm 6.10629, param norm 66.95095, batch time 2.198
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 23, iter 31800, loss 2.99129, smoothed loss 3.26463, grad norm 6.01413, param norm 66.99301, batch time 2.315
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 23, iter 31900, loss 2.96342, smoothed loss 3.25196, grad norm 6.03870, param norm 67.03173, batch time 2.105
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 23, iter 32000, loss 3.61687, smoothed loss 3.28776, grad norm 7.01680, param norm 67.07108, batch time 2.195
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 23, Iter 32000, dev loss: 3.134441
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.85 seconds
Epoch 23, Iter 32000, Train F1 score: 0.731740, Train EM score: 0.593000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 163.66 seconds
Epoch 23, Iter 32000, Dev F1 score: 0.653561, Dev EM score: 0.496920
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 23, iter 32100, loss 3.02713, smoothed loss 3.24129, grad norm 5.96074, param norm 67.10757, batch time 2.375
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 23, iter 32200, loss 3.26451, smoothed loss 3.20720, grad norm 6.42681, param norm 67.14855, batch time 2.361
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 23, iter 32300, loss 3.41771, smoothed loss 3.21627, grad norm 6.37147, param norm 67.17838, batch time 2.202
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 23, iter 32400, loss 2.98169, smoothed loss 3.19359, grad norm 5.88430, param norm 67.21897, batch time 2.220
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 23, iter 32500, loss 2.84850, smoothed loss 3.21989, grad norm 6.11345, param norm 67.25203, batch time 2.225
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 23, iter 32600, loss 3.42553, smoothed loss 3.25991, grad norm 6.44133, param norm 67.28853, batch time 2.422
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 23, iter 32700, loss 3.23555, smoothed loss 3.23471, grad norm 6.83807, param norm 67.32713, batch time 2.310
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 23, iter 32800, loss 3.67157, smoothed loss 3.20254, grad norm 6.60126, param norm 67.36935, batch time 2.272
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 23, iter 32900, loss 2.61341, smoothed loss 3.19021, grad norm 5.23227, param norm 67.40334, batch time 2.310
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 23, iter 33000, loss 2.86988, smoothed loss 3.26639, grad norm 5.44980, param norm 67.44043, batch time 2.149
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 23, Iter 33000, dev loss: 3.127456
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 24.00 seconds
Epoch 23, Iter 33000, Train F1 score: 0.710465, Train EM score: 0.553000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.83 seconds
Epoch 23, Iter 33000, Dev F1 score: 0.651561, Dev EM score: 0.496631
End of epoch 23. Time for epoch: 4083.041983
epoch 24, iter 33100, loss 2.78867, smoothed loss 3.22151, grad norm 6.05730, param norm 67.47715, batch time 2.268
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 24, iter 33200, loss 3.32248, smoothed loss 3.23080, grad norm 6.49670, param norm 67.52024, batch time 2.286
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 24, iter 33300, loss 3.60238, smoothed loss 3.23147, grad norm 6.26774, param norm 67.55752, batch time 2.358
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 24, iter 33400, loss 3.12855, smoothed loss 3.23122, grad norm 6.20074, param norm 67.59180, batch time 2.239
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 24, iter 33500, loss 3.26394, smoothed loss 3.21996, grad norm 6.44328, param norm 67.63045, batch time 2.192
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 24, iter 33600, loss 2.78632, smoothed loss 3.18538, grad norm 5.69306, param norm 67.66917, batch time 2.412
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 24, iter 33700, loss 2.82937, smoothed loss 3.18252, grad norm 5.92153, param norm 67.70361, batch time 2.255
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 24, iter 33800, loss 3.02561, smoothed loss 3.20725, grad norm 5.55396, param norm 67.73159, batch time 2.182
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 24, iter 33900, loss 4.00487, smoothed loss 3.18237, grad norm 6.91254, param norm 67.76987, batch time 2.239
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 24, iter 34000, loss 2.91681, smoothed loss 3.19316, grad norm 6.19504, param norm 67.80963, batch time 2.287
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 24, Iter 34000, dev loss: 3.119876
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.37 seconds
Epoch 24, Iter 34000, Train F1 score: 0.718255, Train EM score: 0.574000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 165.04 seconds
Epoch 24, Iter 34000, Dev F1 score: 0.656537, Dev EM score: 0.499615
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 24, iter 34100, loss 4.02109, smoothed loss 3.23756, grad norm 6.82033, param norm 67.84906, batch time 2.236
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 24, iter 34200, loss 3.00896, smoothed loss 3.22163, grad norm 5.89474, param norm 67.88882, batch time 2.253
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 24, iter 34300, loss 3.43698, smoothed loss 3.21362, grad norm 6.99696, param norm 67.91843, batch time 2.181
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 24, iter 34400, loss 3.30679, smoothed loss 3.23649, grad norm 5.64237, param norm 67.95161, batch time 2.238
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 24. Time for epoch: 3751.891892
epoch 25, iter 34500, loss 3.19754, smoothed loss 3.17283, grad norm 6.17139, param norm 67.99212, batch time 2.287
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 25, iter 34600, loss 3.11637, smoothed loss 3.19786, grad norm 6.30116, param norm 68.03673, batch time 2.170
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 25, iter 34700, loss 2.90721, smoothed loss 3.19000, grad norm 5.79056, param norm 68.07854, batch time 2.380
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 25, iter 34800, loss 2.88110, smoothed loss 3.21100, grad norm 5.91749, param norm 68.11971, batch time 2.366
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 25, iter 34900, loss 3.46398, smoothed loss 3.19788, grad norm 6.21569, param norm 68.15312, batch time 2.340
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 25, iter 35000, loss 3.30027, smoothed loss 3.18509, grad norm 5.93039, param norm 68.19090, batch time 2.197
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 25, Iter 35000, dev loss: 3.131043
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.74 seconds
Epoch 25, Iter 35000, Train F1 score: 0.736227, Train EM score: 0.585000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.31 seconds
Epoch 25, Iter 35000, Dev F1 score: 0.655430, Dev EM score: 0.498268
epoch 25, iter 35100, loss 2.79050, smoothed loss 3.18373, grad norm 6.05532, param norm 68.22592, batch time 2.165
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 25, iter 35200, loss 3.95488, smoothed loss 3.18387, grad norm 7.35729, param norm 68.26075, batch time 2.197
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 25, iter 35300, loss 2.37839, smoothed loss 3.09878, grad norm 6.13996, param norm 68.29999, batch time 2.700
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 25, iter 35400, loss 3.14666, smoothed loss 3.15592, grad norm 5.66826, param norm 68.33300, batch time 2.462
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 25, iter 35500, loss 2.95320, smoothed loss 3.16939, grad norm 5.96425, param norm 68.36761, batch time 2.194
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 25, iter 35600, loss 3.61257, smoothed loss 3.18889, grad norm 6.68606, param norm 68.40907, batch time 2.220
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 25, iter 35700, loss 2.99676, smoothed loss 3.14638, grad norm 6.06661, param norm 68.43907, batch time 2.264
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 25, iter 35800, loss 2.66452, smoothed loss 3.18085, grad norm 6.06494, param norm 68.47585, batch time 2.101
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 25. Time for epoch: 3751.883029
epoch 26, iter 35900, loss 3.27836, smoothed loss 3.18635, grad norm 6.48726, param norm 68.51772, batch time 2.376
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 26, iter 36000, loss 3.46536, smoothed loss 3.15924, grad norm 6.84490, param norm 68.55135, batch time 2.085
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 26, Iter 36000, dev loss: 3.111089
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.29 seconds
Epoch 26, Iter 36000, Train F1 score: 0.737972, Train EM score: 0.577000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.52 seconds
Epoch 26, Iter 36000, Dev F1 score: 0.657764, Dev EM score: 0.502791
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 26, iter 36100, loss 3.00157, smoothed loss 3.18245, grad norm 5.84680, param norm 68.59680, batch time 2.314
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 26, iter 36200, loss 3.14583, smoothed loss 3.17925, grad norm 6.60816, param norm 68.63512, batch time 2.275
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 26, iter 36300, loss 2.39752, smoothed loss 3.17625, grad norm 5.29006, param norm 68.66497, batch time 2.374
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 26, iter 36400, loss 2.65461, smoothed loss 3.15014, grad norm 5.42860, param norm 68.70588, batch time 2.257
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 26, iter 36500, loss 2.83003, smoothed loss 3.14672, grad norm 5.86793, param norm 68.74812, batch time 2.266
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 26, iter 36600, loss 2.34568, smoothed loss 3.12515, grad norm 5.22064, param norm 68.77526, batch time 2.186
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 26, iter 36700, loss 3.38950, smoothed loss 3.16504, grad norm 7.25001, param norm 68.80991, batch time 2.529
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 26, iter 36800, loss 3.10356, smoothed loss 3.15306, grad norm 6.54406, param norm 68.84944, batch time 2.304
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 26, iter 36900, loss 3.32770, smoothed loss 3.14509, grad norm 6.19784, param norm 68.88142, batch time 2.288
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 26, iter 37000, loss 2.86566, smoothed loss 3.16245, grad norm 7.19505, param norm 68.92001, batch time 2.141
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 26, Iter 37000, dev loss: 3.098204
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.47 seconds
Epoch 26, Iter 37000, Train F1 score: 0.737170, Train EM score: 0.590000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 163.81 seconds
Epoch 26, Iter 37000, Dev F1 score: 0.657617, Dev EM score: 0.504812
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 26, iter 37100, loss 2.97157, smoothed loss 3.13661, grad norm 5.93803, param norm 68.95739, batch time 2.252
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 26, iter 37200, loss 3.68199, smoothed loss 3.10607, grad norm 7.54062, param norm 68.98855, batch time 2.476
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 26, iter 37300, loss 2.89644, smoothed loss 3.15494, grad norm 6.36153, param norm 69.02259, batch time 2.134
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 26. Time for epoch: 4089.076057
epoch 27, iter 37400, loss 2.46313, smoothed loss 3.12772, grad norm 5.08763, param norm 69.06027, batch time 2.150
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 27, iter 37500, loss 2.48770, smoothed loss 3.15484, grad norm 5.69277, param norm 69.09907, batch time 2.145
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 27, iter 37600, loss 2.89363, smoothed loss 3.15272, grad norm 6.03620, param norm 69.13641, batch time 2.218
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 27, iter 37700, loss 3.72792, smoothed loss 3.12683, grad norm 7.19572, param norm 69.17110, batch time 2.116
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 27, iter 37800, loss 3.96621, smoothed loss 3.17696, grad norm 7.36198, param norm 69.20609, batch time 2.309
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 27, iter 37900, loss 3.91081, smoothed loss 3.08845, grad norm 7.03517, param norm 69.23920, batch time 2.470
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 27, iter 38000, loss 3.15662, smoothed loss 3.08964, grad norm 6.32143, param norm 69.27648, batch time 2.309
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 27, Iter 38000, dev loss: 3.127070
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 22.92 seconds
Epoch 27, Iter 38000, Train F1 score: 0.745446, Train EM score: 0.605000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 163.40 seconds
Epoch 27, Iter 38000, Dev F1 score: 0.655902, Dev EM score: 0.501732
epoch 27, iter 38100, loss 3.12437, smoothed loss 3.08705, grad norm 7.27665, param norm 69.30814, batch time 2.186
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 27, iter 38200, loss 3.32982, smoothed loss 3.08173, grad norm 6.25657, param norm 69.34626, batch time 2.440
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 27, iter 38300, loss 2.79258, smoothed loss 3.13087, grad norm 6.01214, param norm 69.37879, batch time 2.472
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 27, iter 38400, loss 2.85194, smoothed loss 3.13933, grad norm 6.20837, param norm 69.41109, batch time 2.191
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 27, iter 38500, loss 3.83359, smoothed loss 3.12241, grad norm 6.09054, param norm 69.44605, batch time 2.274
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 27, iter 38600, loss 2.68332, smoothed loss 3.10258, grad norm 6.06090, param norm 69.47772, batch time 2.239
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 27, iter 38700, loss 2.68047, smoothed loss 3.13721, grad norm 5.76548, param norm 69.51225, batch time 2.299
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 27. Time for epoch: 3752.061804
epoch 28, iter 38800, loss 2.86335, smoothed loss 3.09419, grad norm 6.06718, param norm 69.54872, batch time 2.540
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 28, iter 38900, loss 2.87035, smoothed loss 3.11669, grad norm 6.79542, param norm 69.58669, batch time 2.193
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 28, iter 39000, loss 3.12051, smoothed loss 3.12058, grad norm 6.71075, param norm 69.62297, batch time 2.263
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 28, Iter 39000, dev loss: 3.098120
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.66 seconds
Epoch 28, Iter 39000, Train F1 score: 0.741510, Train EM score: 0.612000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 160.70 seconds
Epoch 28, Iter 39000, Dev F1 score: 0.658535, Dev EM score: 0.506930
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 28, iter 39100, loss 3.61352, smoothed loss 3.12254, grad norm 7.26158, param norm 69.65805, batch time 2.465
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 28, iter 39200, loss 3.45162, smoothed loss 3.13802, grad norm 6.58026, param norm 69.69689, batch time 2.520
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 28, iter 39300, loss 3.25251, smoothed loss 3.12411, grad norm 6.48169, param norm 69.73227, batch time 2.190
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 28, iter 39400, loss 2.24119, smoothed loss 3.07142, grad norm 5.81787, param norm 69.76710, batch time 2.107
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 28, iter 39500, loss 2.88773, smoothed loss 3.05663, grad norm 6.25723, param norm 69.79829, batch time 2.282
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 28, iter 39600, loss 3.41878, smoothed loss 3.05790, grad norm 7.04005, param norm 69.83443, batch time 2.299
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 28, iter 39700, loss 2.80457, smoothed loss 3.03754, grad norm 7.13222, param norm 69.87120, batch time 2.082
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 28, iter 39800, loss 2.93113, smoothed loss 3.08737, grad norm 7.30283, param norm 69.90472, batch time 2.218
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 28, iter 39900, loss 2.87193, smoothed loss 3.10228, grad norm 6.72500, param norm 69.93877, batch time 2.168
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 28, iter 40000, loss 2.89027, smoothed loss 3.05799, grad norm 6.00039, param norm 69.97648, batch time 2.229
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 28, Iter 40000, dev loss: 3.096011
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.80 seconds
Epoch 28, Iter 40000, Train F1 score: 0.713740, Train EM score: 0.559000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 161.84 seconds
Epoch 28, Iter 40000, Dev F1 score: 0.661024, Dev EM score: 0.507026
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 28, iter 40100, loss 2.99592, smoothed loss 3.09644, grad norm 6.02858, param norm 70.00671, batch time 2.327
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 28. Time for epoch: 4093.290099
epoch 29, iter 40200, loss 3.57630, smoothed loss 3.12777, grad norm 6.57031, param norm 70.04405, batch time 2.058
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 29, iter 40300, loss 2.68300, smoothed loss 3.09762, grad norm 6.37525, param norm 70.08221, batch time 2.268
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 29, iter 40400, loss 3.11918, smoothed loss 3.07024, grad norm 6.57176, param norm 70.11989, batch time 2.233
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 29, iter 40500, loss 2.90248, smoothed loss 3.09112, grad norm 6.20854, param norm 70.15346, batch time 2.127
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 29, iter 40600, loss 3.22523, smoothed loss 3.12878, grad norm 6.89595, param norm 70.19042, batch time 2.174
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 29, iter 40700, loss 3.25675, smoothed loss 3.06654, grad norm 6.13595, param norm 70.22168, batch time 2.162
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 29, iter 40800, loss 2.85805, smoothed loss 3.04823, grad norm 5.84582, param norm 70.25946, batch time 2.300
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 29, iter 40900, loss 2.95024, smoothed loss 3.04003, grad norm 6.07079, param norm 70.28833, batch time 2.276
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 29, iter 41000, loss 3.07132, smoothed loss 3.08468, grad norm 6.10513, param norm 70.32259, batch time 2.257
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 29, Iter 41000, dev loss: 3.075004
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.90 seconds
Epoch 29, Iter 41000, Train F1 score: 0.726483, Train EM score: 0.587000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 163.87 seconds
Epoch 29, Iter 41000, Dev F1 score: 0.663178, Dev EM score: 0.509240
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 29, iter 41100, loss 3.30836, smoothed loss 3.05089, grad norm 6.42854, param norm 70.35629, batch time 2.133
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 29, iter 41200, loss 2.86548, smoothed loss 3.03829, grad norm 6.65073, param norm 70.39130, batch time 2.409
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 29, iter 41300, loss 3.89010, smoothed loss 3.09061, grad norm 6.78648, param norm 70.42581, batch time 2.290
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 29, iter 41400, loss 2.34728, smoothed loss 3.04679, grad norm 5.66580, param norm 70.45682, batch time 2.075
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 29, iter 41500, loss 2.92267, smoothed loss 3.02469, grad norm 6.28733, param norm 70.49036, batch time 2.118
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 29, iter 41600, loss 3.05100, smoothed loss 3.11566, grad norm 6.44099, param norm 70.52173, batch time 2.073
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 29. Time for epoch: 3758.220639
epoch 30, iter 41700, loss 3.13413, smoothed loss 3.05517, grad norm 6.09199, param norm 70.56071, batch time 2.133
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 30, iter 41800, loss 2.78743, smoothed loss 3.05557, grad norm 6.27812, param norm 70.59229, batch time 2.153
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 30, iter 41900, loss 3.30037, smoothed loss 3.05422, grad norm 6.28197, param norm 70.63187, batch time 2.200
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 30, iter 42000, loss 2.93726, smoothed loss 3.06872, grad norm 5.99712, param norm 70.66641, batch time 2.191
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 30, Iter 42000, dev loss: 3.104395
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 24.33 seconds
Epoch 30, Iter 42000, Train F1 score: 0.767376, Train EM score: 0.624000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.37 seconds
Epoch 30, Iter 42000, Dev F1 score: 0.660557, Dev EM score: 0.505967
epoch 30, iter 42100, loss 3.26670, smoothed loss 3.08964, grad norm 5.66045, param norm 70.69817, batch time 2.303
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 30, iter 42200, loss 3.24661, smoothed loss 3.06872, grad norm 7.05293, param norm 70.73584, batch time 2.218
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 30, iter 42300, loss 3.55834, smoothed loss 3.03733, grad norm 6.64913, param norm 70.76422, batch time 2.125
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 30, iter 42400, loss 3.23646, smoothed loss 3.01470, grad norm 6.61472, param norm 70.79972, batch time 2.231
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 30, iter 42500, loss 3.28722, smoothed loss 3.02261, grad norm 6.51218, param norm 70.83543, batch time 2.294
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 30, iter 42600, loss 3.17982, smoothed loss 3.01226, grad norm 6.17019, param norm 70.86665, batch time 2.390
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 30, iter 42700, loss 3.44972, smoothed loss 3.05547, grad norm 6.83209, param norm 70.90262, batch time 2.214
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 30, iter 42800, loss 3.09824, smoothed loss 3.05948, grad norm 5.94931, param norm 70.93729, batch time 2.350
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 30, iter 42900, loss 2.62094, smoothed loss 3.01824, grad norm 5.62269, param norm 70.97232, batch time 2.341
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 30, iter 43000, loss 4.28736, smoothed loss 3.07267, grad norm 7.40041, param norm 71.00307, batch time 2.088
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 30, Iter 43000, dev loss: 3.053221
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 24.36 seconds
Epoch 30, Iter 43000, Train F1 score: 0.743965, Train EM score: 0.607000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.98 seconds
Epoch 30, Iter 43000, Dev F1 score: 0.663037, Dev EM score: 0.509336
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
End of epoch 30. Time for epoch: 4090.469862
epoch 31, iter 43100, loss 3.24328, smoothed loss 3.01099, grad norm 7.21475, param norm 71.04534, batch time 2.151
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 31, iter 43200, loss 3.17382, smoothed loss 3.00933, grad norm 5.58198, param norm 71.07694, batch time 2.553
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 31, iter 43300, loss 3.20898, smoothed loss 3.07286, grad norm 6.61838, param norm 71.11314, batch time 2.100
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 31, iter 43400, loss 2.71465, smoothed loss 3.02340, grad norm 5.78141, param norm 71.14597, batch time 2.107
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 31, iter 43500, loss 3.17877, smoothed loss 3.05617, grad norm 5.60074, param norm 71.17887, batch time 2.270
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 31, iter 43600, loss 2.98681, smoothed loss 3.00906, grad norm 6.18447, param norm 71.21304, batch time 2.249
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 31, iter 43700, loss 2.74429, smoothed loss 3.01200, grad norm 5.59373, param norm 71.24397, batch time 2.186
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 31, iter 43800, loss 2.57120, smoothed loss 3.02526, grad norm 6.30020, param norm 71.27585, batch time 2.615
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 31, iter 43900, loss 2.59350, smoothed loss 2.97439, grad norm 5.44192, param norm 71.31159, batch time 2.386
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 31, iter 44000, loss 3.36402, smoothed loss 2.98451, grad norm 7.26509, param norm 71.34657, batch time 2.324
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 31, Iter 44000, dev loss: 3.102931
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.78 seconds
Epoch 31, Iter 44000, Train F1 score: 0.751134, Train EM score: 0.605000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.34 seconds
Epoch 31, Iter 44000, Dev F1 score: 0.662108, Dev EM score: 0.507122
epoch 31, iter 44100, loss 3.18154, smoothed loss 3.03502, grad norm 6.59724, param norm 71.38155, batch time 2.321
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 31, iter 44200, loss 3.19336, smoothed loss 3.02255, grad norm 6.66711, param norm 71.41203, batch time 2.257
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 31, iter 44300, loss 3.06020, smoothed loss 3.00596, grad norm 6.83202, param norm 71.44189, batch time 2.260
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 31, iter 44400, loss 3.98863, smoothed loss 3.04613, grad norm 7.97921, param norm 71.47272, batch time 2.301
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 31. Time for epoch: 3743.462824
epoch 32, iter 44500, loss 3.36280, smoothed loss 3.04717, grad norm 6.39862, param norm 71.51351, batch time 2.156
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 32, iter 44600, loss 3.89742, smoothed loss 3.00249, grad norm 6.78226, param norm 71.54984, batch time 2.126
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 32, iter 44700, loss 3.64163, smoothed loss 3.01583, grad norm 7.01890, param norm 71.58398, batch time 2.197
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 32, iter 44800, loss 3.53052, smoothed loss 3.01403, grad norm 6.59258, param norm 71.61840, batch time 2.344
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 32, iter 44900, loss 2.54926, smoothed loss 3.01746, grad norm 5.93846, param norm 71.65176, batch time 2.428
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 32, iter 45000, loss 2.28838, smoothed loss 3.00166, grad norm 5.14194, param norm 71.68036, batch time 2.146
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 32, Iter 45000, dev loss: 3.073086
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.72 seconds
Epoch 32, Iter 45000, Train F1 score: 0.754926, Train EM score: 0.600000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 165.42 seconds
Epoch 32, Iter 45000, Dev F1 score: 0.662842, Dev EM score: 0.507796
epoch 32, iter 45100, loss 3.13705, smoothed loss 2.99690, grad norm 6.29654, param norm 71.71692, batch time 2.332
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 32, iter 45200, loss 2.96686, smoothed loss 2.97852, grad norm 5.68481, param norm 71.74506, batch time 2.270
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 32, iter 45300, loss 2.55236, smoothed loss 2.95646, grad norm 5.18416, param norm 71.77538, batch time 2.182
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 32, iter 45400, loss 2.46419, smoothed loss 2.97386, grad norm 6.20183, param norm 71.81143, batch time 2.178
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 32, iter 45500, loss 2.57586, smoothed loss 2.99703, grad norm 6.67951, param norm 71.83984, batch time 2.117
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 32, iter 45600, loss 2.37634, smoothed loss 3.02707, grad norm 5.89501, param norm 71.87398, batch time 2.362
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 32, iter 45700, loss 3.51702, smoothed loss 2.99027, grad norm 6.32371, param norm 71.91295, batch time 2.151
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 32, iter 45800, loss 2.76348, smoothed loss 2.96955, grad norm 6.26889, param norm 71.94395, batch time 2.220
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 32, iter 45900, loss 2.55026, smoothed loss 2.99620, grad norm 5.74384, param norm 71.97507, batch time 2.438
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 32. Time for epoch: 3754.117075
epoch 33, iter 46000, loss 2.69009, smoothed loss 3.00621, grad norm 5.87144, param norm 72.00714, batch time 2.235
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 33, Iter 46000, dev loss: 3.071803
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 24.03 seconds
Epoch 33, Iter 46000, Train F1 score: 0.742529, Train EM score: 0.600000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.64 seconds
Epoch 33, Iter 46000, Dev F1 score: 0.663736, Dev EM score: 0.509625
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 33, iter 46100, loss 2.52605, smoothed loss 3.01591, grad norm 5.95726, param norm 72.04082, batch time 2.459
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 33, iter 46200, loss 2.80169, smoothed loss 2.97812, grad norm 6.23709, param norm 72.07668, batch time 2.203
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 33, iter 46300, loss 3.02149, smoothed loss 3.00140, grad norm 6.64289, param norm 72.11156, batch time 2.194
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 33, iter 46400, loss 2.37437, smoothed loss 3.00010, grad norm 5.49931, param norm 72.14337, batch time 2.111
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 33, iter 46500, loss 2.13699, smoothed loss 2.96280, grad norm 5.73159, param norm 72.17854, batch time 2.163
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 33, iter 46600, loss 2.77018, smoothed loss 2.96573, grad norm 6.37228, param norm 72.20805, batch time 2.351
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 33, iter 46700, loss 2.71500, smoothed loss 2.95808, grad norm 5.98655, param norm 72.24070, batch time 2.302
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 33, iter 46800, loss 2.99464, smoothed loss 2.96301, grad norm 6.00105, param norm 72.27081, batch time 2.281
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 33, iter 46900, loss 2.27603, smoothed loss 2.93852, grad norm 5.59157, param norm 72.30560, batch time 2.437
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 33, iter 47000, loss 2.75160, smoothed loss 2.95937, grad norm 6.62229, param norm 72.33616, batch time 2.372
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 33, Iter 47000, dev loss: 3.073621
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.59 seconds
Epoch 33, Iter 47000, Train F1 score: 0.721356, Train EM score: 0.586000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 163.93 seconds
Epoch 33, Iter 47000, Dev F1 score: 0.663706, Dev EM score: 0.513090
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 33, iter 47100, loss 3.58637, smoothed loss 2.96840, grad norm 8.02220, param norm 72.36993, batch time 2.316
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 33, iter 47200, loss 3.18207, smoothed loss 2.96073, grad norm 6.90878, param norm 72.40111, batch time 2.156
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 33, iter 47300, loss 3.26416, smoothed loss 3.00870, grad norm 6.53425, param norm 72.43195, batch time 2.269
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 33. Time for epoch: 4080.296433
epoch 34, iter 47400, loss 2.45895, smoothed loss 2.98724, grad norm 6.10208, param norm 72.46998, batch time 2.063
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 34, iter 47500, loss 3.53280, smoothed loss 3.00378, grad norm 7.17856, param norm 72.50167, batch time 2.239
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 34, iter 47600, loss 3.39684, smoothed loss 2.98063, grad norm 7.32764, param norm 72.53471, batch time 2.426
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 34, iter 47700, loss 2.72587, smoothed loss 2.96473, grad norm 6.23539, param norm 72.56068, batch time 2.250
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 34, iter 47800, loss 3.23634, smoothed loss 3.00016, grad norm 6.63260, param norm 72.59632, batch time 2.206
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 34, iter 47900, loss 2.48205, smoothed loss 2.94551, grad norm 7.12681, param norm 72.62830, batch time 2.460
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 34, iter 48000, loss 2.70945, smoothed loss 2.96445, grad norm 5.46485, param norm 72.66045, batch time 2.055
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 34, Iter 48000, dev loss: 3.059025
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.45 seconds
Epoch 34, Iter 48000, Train F1 score: 0.752289, Train EM score: 0.603000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 163.66 seconds
Epoch 34, Iter 48000, Dev F1 score: 0.666641, Dev EM score: 0.510202
epoch 34, iter 48100, loss 2.71551, smoothed loss 2.92972, grad norm 6.54753, param norm 72.69426, batch time 2.214
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 34, iter 48200, loss 3.06070, smoothed loss 2.92900, grad norm 7.20086, param norm 72.72493, batch time 2.184
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 34, iter 48300, loss 2.23645, smoothed loss 2.92374, grad norm 5.29598, param norm 72.75771, batch time 2.352
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 34, iter 48400, loss 3.14223, smoothed loss 2.94054, grad norm 6.61759, param norm 72.78725, batch time 2.143
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 34, iter 48500, loss 2.66242, smoothed loss 2.97074, grad norm 5.68785, param norm 72.81967, batch time 2.219
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 34, iter 48600, loss 3.34517, smoothed loss 2.91790, grad norm 7.51630, param norm 72.85340, batch time 2.375
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 34, iter 48700, loss 3.02804, smoothed loss 2.90956, grad norm 6.00843, param norm 72.88332, batch time 2.204
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 34. Time for epoch: 3743.232618
epoch 35, iter 48800, loss 2.83060, smoothed loss 2.97039, grad norm 6.63016, param norm 72.91702, batch time 2.181
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 35, iter 48900, loss 2.62335, smoothed loss 2.93078, grad norm 5.88137, param norm 72.95065, batch time 2.362
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 35, iter 49000, loss 2.67857, smoothed loss 2.97739, grad norm 6.46931, param norm 72.98273, batch time 2.342
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 35, Iter 49000, dev loss: 3.053668
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.71 seconds
Epoch 35, Iter 49000, Train F1 score: 0.785693, Train EM score: 0.658000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.22 seconds
Epoch 35, Iter 49000, Dev F1 score: 0.664811, Dev EM score: 0.512320
epoch 35, iter 49100, loss 2.67679, smoothed loss 2.93920, grad norm 6.45743, param norm 73.01683, batch time 2.379
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 35, iter 49200, loss 3.27255, smoothed loss 2.94828, grad norm 6.74234, param norm 73.04424, batch time 2.231
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 35, iter 49300, loss 2.70031, smoothed loss 2.94617, grad norm 6.11780, param norm 73.07774, batch time 2.335
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 35, iter 49400, loss 2.44694, smoothed loss 2.90458, grad norm 6.10018, param norm 73.11005, batch time 2.292
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 35, iter 49500, loss 2.90904, smoothed loss 2.90837, grad norm 5.92659, param norm 73.14138, batch time 2.072
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 35, iter 49600, loss 2.46804, smoothed loss 2.90359, grad norm 6.27071, param norm 73.17224, batch time 2.169
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 35, iter 49700, loss 2.24141, smoothed loss 2.86026, grad norm 5.14791, param norm 73.20387, batch time 2.234
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 35, iter 49800, loss 2.46983, smoothed loss 2.95672, grad norm 6.35000, param norm 73.23543, batch time 2.395
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 35, iter 49900, loss 2.58601, smoothed loss 2.94838, grad norm 5.80863, param norm 73.26699, batch time 2.316
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 35, iter 50000, loss 2.79714, smoothed loss 2.90782, grad norm 6.30646, param norm 73.30203, batch time 2.485
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 35, Iter 50000, dev loss: 3.102920
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.60 seconds
Epoch 35, Iter 50000, Train F1 score: 0.750543, Train EM score: 0.604000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 165.06 seconds
Epoch 35, Iter 50000, Dev F1 score: 0.664264, Dev EM score: 0.510876
epoch 35, iter 50100, loss 3.24687, smoothed loss 2.88167, grad norm 6.18792, param norm 73.33384, batch time 2.197
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 35, iter 50200, loss 3.37468, smoothed loss 2.95621, grad norm 7.04456, param norm 73.37003, batch time 2.288
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 35. Time for epoch: 4088.508813
epoch 36, iter 50300, loss 2.53566, smoothed loss 2.92493, grad norm 6.14978, param norm 73.40070, batch time 2.339
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 36, iter 50400, loss 2.91086, smoothed loss 2.93262, grad norm 6.30534, param norm 73.43546, batch time 2.390
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 36, iter 50500, loss 2.15444, smoothed loss 2.92400, grad norm 5.56093, param norm 73.46632, batch time 2.356
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 36, iter 50600, loss 2.61319, smoothed loss 2.95630, grad norm 5.85366, param norm 73.49783, batch time 2.326
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 36, iter 50700, loss 2.52600, smoothed loss 2.93514, grad norm 6.90783, param norm 73.52673, batch time 2.172
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 36, iter 50800, loss 2.71857, smoothed loss 2.92182, grad norm 6.17792, param norm 73.55950, batch time 2.406
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 36, iter 50900, loss 3.31539, smoothed loss 2.86829, grad norm 6.34596, param norm 73.59294, batch time 2.252
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 36, iter 51000, loss 3.20533, smoothed loss 2.88688, grad norm 7.05214, param norm 73.62524, batch time 2.551
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 36, Iter 51000, dev loss: 3.051011
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.28 seconds
Epoch 36, Iter 51000, Train F1 score: 0.755745, Train EM score: 0.613000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 162.46 seconds
Epoch 36, Iter 51000, Dev F1 score: 0.667365, Dev EM score: 0.512512
epoch 36, iter 51100, loss 3.36177, smoothed loss 2.87463, grad norm 7.24951, param norm 73.65617, batch time 2.339
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 36, iter 51200, loss 2.90992, smoothed loss 2.90499, grad norm 6.24682, param norm 73.68678, batch time 2.325
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 36, iter 51300, loss 3.30011, smoothed loss 2.93689, grad norm 7.66716, param norm 73.72123, batch time 2.186
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 36, iter 51400, loss 2.67553, smoothed loss 2.85557, grad norm 6.18389, param norm 73.75507, batch time 2.165
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 36, iter 51500, loss 2.60099, smoothed loss 2.87439, grad norm 5.41778, param norm 73.78687, batch time 2.554
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 36, iter 51600, loss 3.47389, smoothed loss 2.91491, grad norm 6.59063, param norm 73.81822, batch time 2.415
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 36. Time for epoch: 3757.201969
epoch 37, iter 51700, loss 2.77373, smoothed loss 2.90481, grad norm 6.45179, param norm 73.85012, batch time 2.326
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 37, iter 51800, loss 3.21083, smoothed loss 2.89179, grad norm 5.93233, param norm 73.88054, batch time 2.089
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 37, iter 51900, loss 2.62817, smoothed loss 2.91901, grad norm 5.89863, param norm 73.91726, batch time 2.386
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 37, iter 52000, loss 3.13645, smoothed loss 2.91807, grad norm 6.25354, param norm 73.95033, batch time 2.479
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 37, Iter 52000, dev loss: 3.041869
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.35 seconds
Epoch 37, Iter 52000, Train F1 score: 0.771072, Train EM score: 0.629000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 162.03 seconds
Epoch 37, Iter 52000, Dev F1 score: 0.669222, Dev EM score: 0.518191
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 37, iter 52100, loss 2.70019, smoothed loss 2.87755, grad norm 6.25177, param norm 73.98191, batch time 2.279
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 37, iter 52200, loss 3.20124, smoothed loss 2.93211, grad norm 7.37239, param norm 74.00890, batch time 2.232
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 37, iter 52300, loss 3.39408, smoothed loss 2.89042, grad norm 7.19640, param norm 74.04224, batch time 2.364
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 37, iter 52400, loss 2.31530, smoothed loss 2.85313, grad norm 5.34252, param norm 74.06997, batch time 2.143
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 37, iter 52500, loss 2.97159, smoothed loss 2.88660, grad norm 6.73650, param norm 74.10081, batch time 2.167
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 37, iter 52600, loss 2.52375, smoothed loss 2.88971, grad norm 5.81438, param norm 74.12975, batch time 2.410
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 37, iter 52700, loss 2.87806, smoothed loss 2.91596, grad norm 6.29117, param norm 74.16641, batch time 2.269
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 37, iter 52800, loss 2.41327, smoothed loss 2.89324, grad norm 6.11568, param norm 74.19718, batch time 2.413
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 37, iter 52900, loss 2.96301, smoothed loss 2.83810, grad norm 6.54485, param norm 74.22922, batch time 2.329
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 37, iter 53000, loss 2.35912, smoothed loss 2.89759, grad norm 5.71839, param norm 74.25523, batch time 2.351
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 37, Iter 53000, dev loss: 3.076941
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 24.10 seconds
Epoch 37, Iter 53000, Train F1 score: 0.753976, Train EM score: 0.592000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 163.65 seconds
Epoch 37, Iter 53000, Dev F1 score: 0.666635, Dev EM score: 0.514148
End of epoch 37. Time for epoch: 4087.187934
epoch 38, iter 53100, loss 2.30081, smoothed loss 2.91992, grad norm 5.45188, param norm 74.28148, batch time 2.246
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 38, iter 53200, loss 2.72398, smoothed loss 2.91529, grad norm 6.39925, param norm 74.31727, batch time 2.224
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 38, iter 53300, loss 2.73766, smoothed loss 2.86634, grad norm 6.01744, param norm 74.34534, batch time 2.243
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 38, iter 53400, loss 3.88270, smoothed loss 2.88199, grad norm 7.82312, param norm 74.38135, batch time 2.107
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 38, iter 53500, loss 2.91100, smoothed loss 2.89969, grad norm 6.70568, param norm 74.41261, batch time 2.277
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 38, iter 53600, loss 2.26601, smoothed loss 2.87909, grad norm 6.10419, param norm 74.44288, batch time 2.161
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 38, iter 53700, loss 2.72709, smoothed loss 2.85492, grad norm 6.47754, param norm 74.47730, batch time 2.399
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 38, iter 53800, loss 2.06998, smoothed loss 2.88187, grad norm 5.84068, param norm 74.50559, batch time 2.203
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 38, iter 53900, loss 2.58675, smoothed loss 2.84184, grad norm 6.60656, param norm 74.53394, batch time 2.181
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 38, iter 54000, loss 2.18713, smoothed loss 2.81361, grad norm 5.78707, param norm 74.56622, batch time 2.332
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 38, Iter 54000, dev loss: 3.065383
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.86 seconds
Epoch 38, Iter 54000, Train F1 score: 0.767469, Train EM score: 0.629000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 165.36 seconds
Epoch 38, Iter 54000, Dev F1 score: 0.668771, Dev EM score: 0.514918
epoch 38, iter 54100, loss 3.40885, smoothed loss 2.86105, grad norm 7.07516, param norm 74.59747, batch time 2.338
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 38, iter 54200, loss 2.79533, smoothed loss 2.89326, grad norm 6.55260, param norm 74.63234, batch time 2.212
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 38, iter 54300, loss 2.87732, smoothed loss 2.85080, grad norm 6.77220, param norm 74.66833, batch time 2.179
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 38, iter 54400, loss 2.97122, smoothed loss 2.85239, grad norm 6.27068, param norm 74.69359, batch time 2.251
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 38, iter 54500, loss 3.36231, smoothed loss 2.91295, grad norm 7.56440, param norm 74.72019, batch time 2.318
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 38. Time for epoch: 3750.924564
epoch 39, iter 54600, loss 2.63184, smoothed loss 2.91284, grad norm 5.71548, param norm 74.75006, batch time 2.238
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 39, iter 54700, loss 2.84316, smoothed loss 2.84847, grad norm 6.41296, param norm 74.78133, batch time 2.345
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 39, iter 54800, loss 2.99029, smoothed loss 2.88550, grad norm 6.11179, param norm 74.80962, batch time 2.222
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 39, iter 54900, loss 3.11577, smoothed loss 2.85706, grad norm 7.27049, param norm 74.83759, batch time 2.358
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 39, iter 55000, loss 3.17082, smoothed loss 2.89965, grad norm 6.72483, param norm 74.86942, batch time 2.260
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 39, Iter 55000, dev loss: 3.045654
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.65 seconds
Epoch 39, Iter 55000, Train F1 score: 0.763415, Train EM score: 0.619000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.76 seconds
Epoch 39, Iter 55000, Dev F1 score: 0.667888, Dev EM score: 0.515977
epoch 39, iter 55100, loss 3.35314, smoothed loss 2.82862, grad norm 7.18648, param norm 74.89694, batch time 2.194
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 39, iter 55200, loss 2.61942, smoothed loss 2.85118, grad norm 5.72053, param norm 74.92970, batch time 2.108
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 39, iter 55300, loss 3.13839, smoothed loss 2.84782, grad norm 7.05791, param norm 74.95603, batch time 2.344
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 39, iter 55400, loss 2.38623, smoothed loss 2.83184, grad norm 5.64191, param norm 74.98696, batch time 2.310
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 39, iter 55500, loss 3.23639, smoothed loss 2.85154, grad norm 7.15784, param norm 75.01759, batch time 2.295
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 39, iter 55600, loss 3.14723, smoothed loss 2.89535, grad norm 7.63476, param norm 75.04838, batch time 2.479
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 39, iter 55700, loss 3.00805, smoothed loss 2.85305, grad norm 6.16598, param norm 75.08248, batch time 2.611
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 39, iter 55800, loss 2.13673, smoothed loss 2.82287, grad norm 6.14889, param norm 75.11430, batch time 2.192
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 39, iter 55900, loss 3.04088, smoothed loss 2.87217, grad norm 6.91773, param norm 75.14359, batch time 2.941
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 39. Time for epoch: 3756.294361
epoch 40, iter 56000, loss 3.12576, smoothed loss 2.84762, grad norm 7.90421, param norm 75.17845, batch time 2.389
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 40, Iter 56000, dev loss: 3.075605
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.91 seconds
Epoch 40, Iter 56000, Train F1 score: 0.778266, Train EM score: 0.637000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 165.01 seconds
Epoch 40, Iter 56000, Dev F1 score: 0.669666, Dev EM score: 0.519538
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
epoch 40, iter 56100, loss 2.68366, smoothed loss 2.83504, grad norm 5.84575, param norm 75.21038, batch time 2.358
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 40, iter 56200, loss 2.67657, smoothed loss 2.82773, grad norm 5.59616, param norm 75.23975, batch time 2.257
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 40, iter 56300, loss 2.72656, smoothed loss 2.85614, grad norm 6.11891, param norm 75.27158, batch time 2.230
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 40, iter 56400, loss 3.09832, smoothed loss 2.87800, grad norm 6.70488, param norm 75.29981, batch time 2.239
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 40, iter 56500, loss 2.57986, smoothed loss 2.87713, grad norm 5.32728, param norm 75.32871, batch time 2.227
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 40, iter 56600, loss 2.66512, smoothed loss 2.83990, grad norm 6.07864, param norm 75.36497, batch time 2.439
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 40, iter 56700, loss 3.19068, smoothed loss 2.80805, grad norm 7.71310, param norm 75.39429, batch time 2.337
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 40, iter 56800, loss 2.83966, smoothed loss 2.82392, grad norm 5.95676, param norm 75.42188, batch time 2.417
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 40, iter 56900, loss 2.61071, smoothed loss 2.84160, grad norm 5.84995, param norm 75.45182, batch time 2.081
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 40, iter 57000, loss 3.09583, smoothed loss 2.84611, grad norm 7.08009, param norm 75.48096, batch time 2.243
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 40, Iter 57000, dev loss: 3.023672
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 24.10 seconds
Epoch 40, Iter 57000, Train F1 score: 0.783984, Train EM score: 0.639000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.26 seconds
Epoch 40, Iter 57000, Dev F1 score: 0.670711, Dev EM score: 0.518287
epoch 40, iter 57100, loss 2.55729, smoothed loss 2.85412, grad norm 6.26149, param norm 75.51284, batch time 2.258
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 40, iter 57200, loss 2.99683, smoothed loss 2.81850, grad norm 6.96956, param norm 75.54432, batch time 2.294
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 40, iter 57300, loss 3.67003, smoothed loss 2.86987, grad norm 6.86239, param norm 75.56945, batch time 2.139
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 40, iter 57400, loss 3.08928, smoothed loss 2.84440, grad norm 7.14035, param norm 75.60221, batch time 2.143
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 40. Time for epoch: 4093.684517
epoch 41, iter 57500, loss 3.09832, smoothed loss 2.81534, grad norm 6.62395, param norm 75.63354, batch time 2.230
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 41, iter 57600, loss 3.18958, smoothed loss 2.81390, grad norm 6.60563, param norm 75.66541, batch time 2.289
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 41, iter 57700, loss 2.35313, smoothed loss 2.81064, grad norm 5.31835, param norm 75.69399, batch time 2.423
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 41, iter 57800, loss 3.23260, smoothed loss 2.82499, grad norm 7.40244, param norm 75.72281, batch time 2.271
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 41, iter 57900, loss 2.66410, smoothed loss 2.85192, grad norm 6.85594, param norm 75.75790, batch time 2.366
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 41, iter 58000, loss 3.08727, smoothed loss 2.80529, grad norm 7.51348, param norm 75.78815, batch time 2.232
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 41, Iter 58000, dev loss: 3.036603
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.64 seconds
Epoch 41, Iter 58000, Train F1 score: 0.783664, Train EM score: 0.633000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 165.26 seconds
Epoch 41, Iter 58000, Dev F1 score: 0.672308, Dev EM score: 0.516266
epoch 41, iter 58100, loss 2.59233, smoothed loss 2.81804, grad norm 5.77378, param norm 75.81496, batch time 2.150
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 41, iter 58200, loss 3.03705, smoothed loss 2.81999, grad norm 6.19415, param norm 75.84480, batch time 2.382
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 41, iter 58300, loss 2.44658, smoothed loss 2.79008, grad norm 5.91331, param norm 75.87376, batch time 2.139
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 41, iter 58400, loss 2.62219, smoothed loss 2.80975, grad norm 6.41180, param norm 75.90616, batch time 2.374
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 41, iter 58500, loss 2.67835, smoothed loss 2.86755, grad norm 6.30892, param norm 75.93531, batch time 2.196
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 41, iter 58600, loss 2.94977, smoothed loss 2.82368, grad norm 6.04290, param norm 75.96392, batch time 2.122
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 41, iter 58700, loss 2.76992, smoothed loss 2.82365, grad norm 7.07049, param norm 75.99301, batch time 2.283
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 41, iter 58800, loss 2.26160, smoothed loss 2.86357, grad norm 6.24225, param norm 76.02189, batch time 2.419
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 41. Time for epoch: 3756.569090
epoch 42, iter 58900, loss 3.04254, smoothed loss 2.79480, grad norm 6.89220, param norm 76.05499, batch time 2.265
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 42, iter 59000, loss 2.42684, smoothed loss 2.81725, grad norm 5.79407, param norm 76.08535, batch time 2.495
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 42, Iter 59000, dev loss: 3.058443
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 24.03 seconds
Epoch 42, Iter 59000, Train F1 score: 0.766209, Train EM score: 0.629000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.78 seconds
Epoch 42, Iter 59000, Dev F1 score: 0.668912, Dev EM score: 0.517613
epoch 42, iter 59100, loss 2.89393, smoothed loss 2.83660, grad norm 6.45488, param norm 76.11708, batch time 2.330
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 42, iter 59200, loss 2.88607, smoothed loss 2.80862, grad norm 7.04802, param norm 76.14491, batch time 2.277
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 42, iter 59300, loss 2.64020, smoothed loss 2.85497, grad norm 6.11653, param norm 76.17149, batch time 2.309
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 42, iter 59400, loss 2.90592, smoothed loss 2.83441, grad norm 6.77912, param norm 76.20162, batch time 2.318
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 42, iter 59500, loss 3.20944, smoothed loss 2.78337, grad norm 6.53915, param norm 76.23431, batch time 2.184
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 42, iter 59600, loss 2.64673, smoothed loss 2.78916, grad norm 6.27086, param norm 76.25996, batch time 2.394
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 42, iter 59700, loss 2.24461, smoothed loss 2.76873, grad norm 6.34212, param norm 76.28945, batch time 2.219
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 42, iter 59800, loss 3.29611, smoothed loss 2.80678, grad norm 7.45557, param norm 76.31881, batch time 2.498
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 42, iter 59900, loss 2.72518, smoothed loss 2.82171, grad norm 6.45143, param norm 76.34766, batch time 2.224
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 42, iter 60000, loss 2.85061, smoothed loss 2.79489, grad norm 6.42474, param norm 76.37952, batch time 2.136
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 42, Iter 60000, dev loss: 3.047077
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.39 seconds
Epoch 42, Iter 60000, Train F1 score: 0.784968, Train EM score: 0.639000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 164.12 seconds
Epoch 42, Iter 60000, Dev F1 score: 0.670050, Dev EM score: 0.515592
epoch 42, iter 60100, loss 2.01675, smoothed loss 2.75858, grad norm 5.80456, param norm 76.40741, batch time 2.602
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 42, iter 60200, loss 2.70695, smoothed loss 2.83454, grad norm 6.21151, param norm 76.43530, batch time 2.347
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 42. Time for epoch: 4104.128857
epoch 43, iter 60300, loss 2.76729, smoothed loss 2.87776, grad norm 6.10673, param norm 76.46453, batch time 2.489
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 43, iter 60400, loss 2.48276, smoothed loss 2.80596, grad norm 6.02281, param norm 76.49480, batch time 2.351
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 43, iter 60500, loss 2.63765, smoothed loss 2.78371, grad norm 6.05469, param norm 76.52324, batch time 2.186
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 43, iter 60600, loss 2.80045, smoothed loss 2.82312, grad norm 7.09243, param norm 76.55396, batch time 2.209
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 43, iter 60700, loss 2.09470, smoothed loss 2.83018, grad norm 5.67013, param norm 76.58244, batch time 2.200
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 43, iter 60800, loss 2.60432, smoothed loss 2.79769, grad norm 5.88734, param norm 76.61088, batch time 2.382
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 43, iter 60900, loss 2.74072, smoothed loss 2.77545, grad norm 6.57199, param norm 76.63940, batch time 2.401
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 43, iter 61000, loss 3.26391, smoothed loss 2.75300, grad norm 6.51214, param norm 76.66790, batch time 2.375
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 43, Iter 61000, dev loss: 3.055262
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.66 seconds
Epoch 43, Iter 61000, Train F1 score: 0.785818, Train EM score: 0.649000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 165.86 seconds
Epoch 43, Iter 61000, Dev F1 score: 0.670314, Dev EM score: 0.515881
epoch 43, iter 61100, loss 3.30656, smoothed loss 2.76960, grad norm 7.18122, param norm 76.69785, batch time 2.373
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 43, iter 61200, loss 2.57500, smoothed loss 2.75382, grad norm 6.27831, param norm 76.72726, batch time 2.794
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 43, iter 61300, loss 2.25631, smoothed loss 2.78819, grad norm 5.64291, param norm 76.75713, batch time 2.247
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 43, iter 61400, loss 2.72313, smoothed loss 2.79997, grad norm 6.84221, param norm 76.78508, batch time 2.756
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 43, iter 61500, loss 2.56473, smoothed loss 2.74720, grad norm 6.93878, param norm 76.81619, batch time 2.199
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 43, iter 61600, loss 3.00990, smoothed loss 2.80163, grad norm 6.45235, param norm 76.84462, batch time 2.100
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 43, iter 61700, loss 3.66216, smoothed loss 2.83351, grad norm 6.68715, param norm 76.87396, batch time 2.258
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
End of epoch 43. Time for epoch: 3752.507109
epoch 44, iter 61800, loss 2.39520, smoothed loss 2.79705, grad norm 6.29245, param norm 76.90241, batch time 2.292
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 44, iter 61900, loss 2.99371, smoothed loss 2.77892, grad norm 6.99925, param norm 76.92871, batch time 2.408
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 44, iter 62000, loss 3.00504, smoothed loss 2.76521, grad norm 7.00586, param norm 76.95582, batch time 2.202
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 44, Iter 62000, dev loss: 3.061533
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 23.15 seconds
Epoch 44, Iter 62000, Train F1 score: 0.778991, Train EM score: 0.632000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 165.39 seconds
Epoch 44, Iter 62000, Dev F1 score: 0.669956, Dev EM score: 0.518768
epoch 44, iter 62100, loss 2.49293, smoothed loss 2.81562, grad norm 6.25444, param norm 76.98499, batch time 2.336
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 44, iter 62200, loss 2.63798, smoothed loss 2.77307, grad norm 6.35657, param norm 77.01402, batch time 2.365
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 44, iter 62300, loss 3.05980, smoothed loss 2.75135, grad norm 7.07517, param norm 77.04240, batch time 2.549
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 44, iter 62400, loss 3.35176, smoothed loss 2.77771, grad norm 7.03735, param norm 77.06790, batch time 2.193
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 44, iter 62500, loss 2.93571, smoothed loss 2.76968, grad norm 6.61716, param norm 77.10183, batch time 2.606
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 44, iter 62600, loss 2.44547, smoothed loss 2.76640, grad norm 5.95878, param norm 77.12685, batch time 2.195
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 44, iter 62700, loss 2.94253, smoothed loss 2.76535, grad norm 7.25069, param norm 77.15932, batch time 2.458
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 44, iter 62800, loss 2.80022, smoothed loss 2.81603, grad norm 7.53606, param norm 77.19242, batch time 2.240
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 44, iter 62900, loss 2.94735, smoothed loss 2.76628, grad norm 6.77643, param norm 77.22182, batch time 2.282
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
epoch 44, iter 63000, loss 2.71696, smoothed loss 2.78232, grad norm 6.55598, param norm 77.24928, batch time 2.283
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/qa.ckpt...
Calculating dev loss...
Epoch 44, Iter 63000, dev loss: 3.029219
Calculating F1/EM for 1000 examples in train set...
Calculating F1/EM for 1000 examples in train set took 24.10 seconds
Epoch 44, Iter 63000, Train F1 score: 0.772411, Train EM score: 0.627000
Calculating F1/EM for all examples in dev set...
Calculating F1/EM for 10390 examples in dev set took 163.47 seconds
Epoch 44, Iter 63000, Dev F1 score: 0.673674, Dev EM score: 0.520212
Saving to ../experiments/bidadf_ansptr_dp_pred_no_char_cnn/best_checkpoint/qa_best.ckpt...
